
# 💼 ex2.md - 挑戰二：融合監督與非監督學習報告（強化版 + 精準結果）
> 📌 本報告說明如何融合多種異常偵測方法以提升信用卡詐欺偵測模型的精準度與整體效能。

---

## 👤 基本資訊
- 作者：[周庭嫻ACS111125]
- 作業名稱：挑戰二 - 信用卡詐欺融合模型

---

## 🎯 任務目標

本次挑戰目的為整合非監督式異常偵測模型與監督式分類器，提升在極端不平衡資料中偵測詐欺交易的能力，尤其著重於 Precision 的提升。

---

## 📦 使用資料集

- 資料來源：[Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- 總筆數：284,807 筆
- 欄位數量：30（含 Amount 欄，經標準化處理）
- 詐欺比例：約 0.172%（極度不平衡）

---

## 🧪 特徵工程與模型設計

本次實作融合多種非監督式異常偵測技術來擴增特徵空間，提供 XGBoost 模型更豐富的資訊來源。

### 非監督特徵工程：

| 方法              | 說明                                       |
|-------------------|--------------------------------------------|
| Isolation Forest  | 產出 IsoOutlier + AnomalyScore 兩種特徵     |
| KMeans Clustering | 加入群集編號作為特徵                        |
| One-Class SVM     | 產出 OCSVM_Score（異常距離）               |
| Random Forest     | RF_Anomaly 為其對詐欺的預測分數             |

### 監督分類器：

- 主模型：XGBoost
- 重要參數：
  - `scale_pos_weight = 578.55`（自動計算詐欺樣本不平衡比）
  - `n_estimators = 500`
  - `max_depth = 8`
  - `learning_rate = 0.05`

---

## ⚙️ 評估流程與門檻策略

- 使用預設門檻 0.5 先行評估
- 接著使用 `precision_recall_curve` 掃描所有門檻
- 依據 F1-score 最佳值進行門檻優化
- 額外提供高精度模式（Precision ≥ 0.95）

---

## 📊 模型評估結果（門檻 0.5）

```
Accuracy   : 0.9995
Precision  : 0.9725
Recall     : 0.7162
F1 Score   : 0.8249
```

| 類別 | precision | recall | f1-score | support |
|------|-----------|--------|----------|---------|
| 0    | 1.00      | 1.00   | 1.00     | 85295   |
| 1    | 0.972     | 0.716  | 0.825    | 148     |

> ✅ 該模型在極度不平衡下仍保有 0.972 的 Precision 與良好的 F1 Score，顯示融合特徵有效提升分類品質。

---

## 🧠 模型選擇建議

- 若 **精準率（Precision）為優先考量**（例如降低誤報），目前模型已能達成良好效果（Precision > 0.97）
- 若 **召回率（Recall）也很重要**，可透過門檻調整或採用最佳 F1 點進行微調

---

## 📂 檔案結構

```
<學號>_ex2/
├── ex2.ipynb         # 主程式碼（融合模型）
├── ex2.md            # 說明文件（本檔案）
```

---

## ✅ 結論

本挑戰成功透過多種非監督特徵結合 XGBoost 模型，於詐欺偵測任務中取得高 Precision 的穩健表現，並保持良好的 Recall 與整體準確率，適合應用於實際詐欺防制系統中。

