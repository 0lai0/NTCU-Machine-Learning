# 信用卡詐欺預測分析：XGBoost 模型應用

## 專案簡介
本專案致力於建立一個能有效預測信用卡詐欺行為的模型，使用 Kaggle 所提供的資料集進行實作。該資料集真實模擬信用卡交易行為，但包含的詐欺樣本極少，造成正負類別高度不平衡，為模型設計帶來挑戰。

為解決此問題，本專案採用 XGBoost 演算法作為主要模型，並透過類別加權的方式強化對少數類別（詐欺）的識別能力。

---

## 技術流程說明

### 資料來源
- 資料集來自 Kaggle：「Credit Card Fraud Detection Dataset」
- 資料特徵為匿名化後的主成分（V1~V28）與原始交易金額（Amount）、時間（Time）及標記類別（Class）

### 資料前處理步驟
1. **欄位處理**：
   - 移除 `Time` 欄位，避免時間對模型造成偏見。
2. **數值標準化**：
   - 使用 `StandardScaler` 對 `Amount` 欄位標準化，避免數值尺度對模型影響。
3. **資料分割**：
   - 使用 `train_test_split` 將資料以 7:3 比例切分為訓練集與測試集，並設置隨機種子（random_state=42）確保可重現性。

---

## 模型訓練與設計

### 使用演算法
- **XGBoost（Extreme Gradient Boosting）**：
  - 是一種增強型樹模型，以梯度提升為基礎，在效能與準確度方面表現卓越。
  - 特別適合處理類別不平衡的分類問題。

### 不平衡資料處理
- 計算訓練集中正負樣本比例
- 使用 `scale_pos_weight` 參數調整正類樣本權重，使模型更關注詐欺樣本

### 模型訓練步驟
1. 初始化 `XGBClassifier`，設定關鍵參數（見下表）
2. 使用訓練資料進行模型擬合
3. 使用測試資料評估模型效能

---

## 主要模型參數

| 參數               | 說明                                                         |
|--------------------|--------------------------------------------------------------|
| `n_estimators`     | 樹的總數，決定模型複雜度與訓練時間                           |
| `learning_rate`    | 每棵樹對最終預測的貢獻程度，小值增加模型穩定性但訓練較慢       |
| `max_depth`        | 單棵樹的最大深度，控制過擬合風險                             |
| `scale_pos_weight` | 正樣本權重比例，用來處理類別不平衡問題                       |
| `random_state`     | 控制隨機性，確保實驗可重現                                   |
| `eval_metric`      | 設定評估指標，如 `logloss` 或 `auc`                          |

---

## 模型評估指標

完成模型訓練後，評估指標將涵蓋：

- **Accuracy**：整體預測正確率
- **Precision**：被預測為詐欺中實際為詐欺的比例
- **Recall**：實際詐欺中被成功偵測的比例（關鍵）
- **F1 Score**：Precision 與 Recall 的加權平均
- **Classification Report**：顯示每類別的完整評估
- **Precision-Recall Curve**：幫助決定最佳 threshold 的圖形化工具

---

## 執行環境與依賴套件
本專案主要使用以下 Python 套件：

- `pandas`：資料處理
- `numpy`：數學運算
- `scikit-learn`：資料切分與指標評估
- `xgboost`：模型建構
- `kagglehub`：自動下載資料集

---

## 使用方式

1. 安裝所有必要套件（建議使用 pip 或在 Colab 執行）
2. 執行程式碼以載入資料、進行預處理與模型訓練
3. 觀察分類報告與 Precision-Recall 指標調整模型
4. 可透過閾值調整（例如 0.43）進行 Precision 與 Recall 間的權衡
5. 如有需要，可結合其他模型進行混合學習（例如與 Isolation Forest）

---

## 延伸建議

- 可導入 PCA（主成分分析）進行降維處理，加速訓練與視覺化
- 使用 SMOTE 合成少數類別樣本，提升模型泛化能力
- 可引入貝葉斯最佳化（如 Optuna）自動調參數
- 結合非監督方法如 LOF、KMeans 輔助標記資料或進行異常偵測

---

## 參考來源

- Kaggle Dataset: https://www.kaggle.com/mlg-ulb/creditcardfraud
- XGBoost 官方說明文件：https://xgboost.readthedocs.io/
- Scikit-learn 官方文件：https://scikit-learn.org/
