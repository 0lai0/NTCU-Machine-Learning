## 1. 前言與目標

本報告旨在說明在信用卡詐騙偵測任務中，如何透過參數調校來優化非監督式學習模型 KMeans 的效能。
由於 KMeans 本身是分群演算法，並非直接用於分類，我們將透過特定的標籤對齊策略 (label alignment) 將其分群結果映射到詐騙/正常交易的二元類別上。
主要目標是評估 KMeans 在此任務上的潛力，並嘗試提高對詐騙交易的檢測能力 (召回率)，同時關注 F1-score 和精確率。
由於資料集存在嚴重的類別不平衡問題，這對非監督式方法的應用和評估帶來了額外的挑戰。

## 2. 資料集特性

使用的資料集為 `mlg-ulb/creditcardfraud`，其主要特性如下：

* 移除了 'Time' 特徵。
* 對 'Amount' 特徵進行了 StandardScaler 標準化。
* 資料集極度不平衡：
  * 詐騙交易 (Class=1): 492 筆
  * 正常交易 (Class=0): 284315 筆
  * 詐騙交易佔比約 0.173%，這對模型訓練和評估提出了挑戰。

## 3. 基準模型 (KMeans - 範例程式部分)

* **資料處理**:
  * 使用 `train_test_split` (test_size=0.3, stratify=y) 分割資料。
  * 對 `x_train`, `x_test` 進行 StandardScaler 標準化。
  * **KMeans 訓練資料**: 從標準化後的 `x_train` 中選取前 1000 筆正常交易 (`y_train == 0`)，即 `n_x_train`。
* **參數**:
  * `n_clusters`: 透過 `silhouette_score` 在 `n_x_train` 上對 `k` 從 2 到 4 進行評估，選定 `optimal_k`
  * `init='k-means++'`
  * `random_state=RANDOM_SEED` (42)
* **標籤對齊**: 使用 `align_labels` 函數，將 KMeans 預測的叢集標籤對齊到真實的詐騙/正常標籤。
* **測試集表現 (針對詐騙類別 Class=1, 根據 cell 8 輸出)**:
  * Accuracy: 0.9987
  * Precision: 0.783
  * Recall: 0.365
  * F1-score: 0.498

## 4. 參數調校策略與過程 (KMeans)

我的策略是基於基準模型的資料處理流程，額外引入 PCA 降維，然後針對 `n_clusters` 和 `n_init` 參數進行調校。KMeans 的訓練仍然只使用部分正常交易資料。

### 4.1 資料集處理 (調參時)

參數調校過程中，資料處理步驟如下：

1. **資料分割**: 使用 `train_test_split` (test_size=0.3, random_state=RANDOM_SEED, stratify=y) 將完整資料集分割為 `x_train`, `x_test`, `y_train`, `y_test`。
2. **標準化**: 對 `x_train` 和 `x_test` 進行 `StandardScaler` 標準化。
3. **PCA降維**: 對標準化後的 `x_train` 和 `x_test` 進行 `PCA(n_components=25)` 降維。
4. **KMeans訓練資料**: 從降維且標準化後的 `x_train` (即 `pca.fit_transform(scaler.fit_transform(x_train_orig))` ) 中選取 `y_train == 0` 的前 1000 筆資料 (`n_x_train`) 用於訓練 KMeans。

### 4.2 參數調校函數

定義了一個 `tune_km_param` 函數，該函數：

1. 接收參數名稱、參數值範圍、固定的KMeans參數、完整的X和y。
2. 在函數內部，它會重新進行資料分割、標準化和PCA降維。
3. 使用 `n_x_train`（1000筆正常交易PCA特徵）訓練 KMeans。
4. 在 `x_test`（PCA特徵）上進行預測。
5. 使用 `align_labels` 函數對齊預測標籤。
6. 計算並返回在 `y_test` 上的 F1-score。
7. 繪製參數值與F1-score的關係圖。

### 4.3 `n_clusters` 調校

`n_clusters` (K值) 代表分群的數量。

* **固定參數**: `init='k-means++'`, `random_state=RANDOM_SEED`。
* **調校資料**: `n_x_train`。
* **評估方式**: `tune_km_param` 函數在 `x_test` (PCA特徵) 上評估 F1-score。
* **測試範圍**: `range(2, 20)`
  * **最終選定 `n_clusters`**: 3 (F1-score: 0.5114)

### 4.4 `n_init` 調校

`n_init` 代表使用不同中心點初始化的KMeans演算法的運行次數，最終選擇SSE最小的結果。

* **固定參數**: `init='k-means++'`, `random_state=RANDOM_SEED`, `n_clusters=3`。
* **調校資料**: `n_x_train` (同上)。
* **評估方式**: `tune_km_param` 函數在 `x_test` (PCA特徵) 上評估 F1-score。
* **測試範圍**: `range(10, 50, 5)` (即 `[10, 15, 20, ..., 45]`)
  * **最終選定 `n_init`**: 10 (F1-score: 0.5114)
  * 註：F1-score並未因 `n_init` 的改變而提升，`n_init=10` 是 `sklearn` KMeans 的預設值。

### 4.5 KMeans 調校後結果

* **最終參數**:
  * `n_clusters`: 3
  * `init`: 'k-means++'
  * `n_init`: 10
  * `random_state`: 42
* **資料處理**: 採用 4.1 節所述的完整流程，包含標準化和 PCA(n_components=25)。KMeans 仍使用 `n_x_train` (PCA降維後的1000筆正常交易) 進行訓練。
* **標籤對齊**: `align_labels` 函數使用基準模型階段計算出的 `optimal_k` (很可能為3) 來對齊叢集。
* **測試集表現 (針對詐騙類別 Class=1, 根據 cell 14 輸出)**:
  * Accuracy: 0.9987
  * Precision: 0.789
  * Recall: 0.378
  * F1-score: 0.511

## 5. 結果比較與分析

* **基準 KMeans (無PCA, optimal_k由silhouette決定, 可能為3)**:
  * Precision: 0.783
  * Recall: 0.365
  * F1-score: 0.498
* **調校後 KMeans (含PCA(n=25), n_clusters=3, n_init=10)**:
  * Precision: 0.789
  * Recall: 0.378
  * F1-score: 0.511

**分析**:

1. **PCA的引入與參數調校的影響**：
    * 在KMeans的訓練資料中引入PCA (n_components=25) 並選擇 `n_clusters=3` 後，模型的 F1-score 從 0.498 輕微提升至 0.511。召回率和精確率也有小幅改善。
    * `n_init` 的調整在此案例中未帶來 F1-score 的提升。
2. **KMeans的侷限性**：
    * KMeans 作為一種非監督式分群演算法，其目標是最小化群內平方和，而非直接優化分類指標。在本案例中，僅使用正常交易資料進行訓練，期望詐騙交易能被識別為遠離正常群集的點或形成自己的小群集。
    * `align_labels` 函數的有效性取決於詐騙交易是否能在至少一個群集中佔多數。如果詐騙交易分散或與大量正常交易混合在同一群集，則很難被正確識別。
    * 儘管進行了調參，KMeans 在召回率 (0.378) 和 F1-score (0.511) 方面的表現遠不如典型的監督式學習方法。這突顯了在詐騙偵測這類高度不平衡且需要高召回率的任務中，非監督式方法的挑戰。

## 6. 結論與未來方向

本次對 KMeans 模型的參數調校過程中：

1. 在基準模型上，KMeans 使用標準化後的原始特徵（的前1000筆正常交易）進行訓練，獲得 F1-score 為 0.498。
2. 調校過程中，引入了 PCA (n_components=25) 處理特徵，並在經PCA降維後的1000筆正常交易上訓練KMeans。找到了較優的 `n_clusters=3` (F1-score: 0.511)。`n_init` 的調整未帶來進一步改善。

**結論**：

* 透過引入 PCA 和調整 `n_clusters`，KMeans 模型的 F1-score 有微小提升 (從 0.498 到 0.511)。
* 儘管有所提升，KMeans 在詐騙偵測任務中的整體表現（尤其是召回率）與監督式學習模型相比仍有較大差距。這主要是由於其非監督特性和標籤對齊策略的內在限制。
