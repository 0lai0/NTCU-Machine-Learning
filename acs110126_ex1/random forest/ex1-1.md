## 1. 前言與目標

本報告旨在說明在信用卡詐騙偵測任務中，如何透過參數調校來優化機器學習模型的效能。
主要目標是提高對詐騙交易的檢測能力，同時盡可能減少對正常交易的誤判。
由於資料集存在嚴重的類別不平衡問題，我將重點關注 F1-score、召回率 (Recall) 和精確率 (Precision) 等指標。

## 2. 資料集特性

使用的資料集為 `mlg-ulb/creditcardfraud`，其主要特性如下：

* 移除了 'Time' 特徵。
* 對 'Amount' 特徵進行了 StandardScaler 標準化。
* 資料集極度不平衡：
  * 詐騙交易 (Class=1): 492 筆
  * 正常交易 (Class=0): 284315 筆
  * 詐騙交易佔比約 0.173%，這對模型訓練和評估提出了挑戰。

## 3. 基準模型 (範例)

範例中提供了一個 Random Forest 分類器作為基準：

* 參數: `n_estimators=100`, `random_state=RANDOM_SEED`
* 訓練資料: 完整訓練集
* 測試集表現 (針對詐騙類別 Class=1):
  * Accuracy: 0.9996
  * Precision: 0.941
  * Recall: 0.824
  * F1-score: 0.878

## 4. 參數調校策略與過程 (Random Forest)

我的策略是首先使用下採樣後的平衡資料集進行初步的參數範圍探索 (針對 `n_estimators` 和 `max_depth`)，以加速交叉驗證過程。
然後，在完整的訓練集上，針對不平衡問題調整 `class_weight` 參數，並使用先前找到的最佳參數組合。

### 4.1 資料集處理：下採樣 (Undersampling)

為了加速 `n_estimators` 和 `max_depth` 的交叉驗證調校過程，我對多數類別 (正常交易) 進行了下採樣：

* 詐騙交易 (Class=1): 492 筆 (全部保留)
* 正常交易 (Class=0): 下採樣至 1500 筆
* 下採樣後的訓練資料中，正常交易與詐騙交易的比例約為 3:1。
* 使用 `train_test_split` (test_size=0.3, stratify=under_y) 將下採樣後的資料集分割為 `under_x_train`, `under_y_train`, `under_x_test`, `under_y_test`。

### 4.2 參數調校函數

我定義了一個 `tune_param` 函數，該函數使用 `StratifiedKFold` (5折交叉驗證) 和 `cross_val_score` (評估指標為 'f1') 來尋找給定參數範圍內的最優值。

### 4.3 `n_estimators` 調校

`n_estimators` 代表森林中樹的數量。太少可能導致欠擬合，太多則可能增加計算成本且邊際效益遞減。

* **固定參數**: `random_state=RANDOM_SEED`, `n_jobs=-1`, `class_weight='balanced'` (在下採樣資料集上使用 'balanced' 有助於進一步平衡)。
* **調校資料**: `under_x_train`, `under_y_train`
* **第一輪範圍**: `[100, 200, 300, 400, 500]` (間隔 100)
  * 最佳值: 300 (CV F1-score: 0.9210)
* **第二輪精細範圍**: `[205, 210, ..., 305]` (基於第一輪結果，間隔 5，範圍從 `best_n - 50` 到 `best_n + 50`)
  * **最終選定 `n_estimators`**: 255 (CV F1-score: 0.9210)

### 4.4 `max_depth` 調校

`max_depth` 控制樹的最大深度。較淺的樹可能欠擬合，較深的樹可能過擬合。

* **固定參數**: `random_state=RANDOM_SEED`, `n_jobs=-1`, `class_weight='balanced'`, `n_estimators=255`
* **調校資料**: `under_x_train`, `under_y_train`
* **範圍**: `[5, 10, 15, 20, 25, 30]` (間隔 5)
  * **最終選定 `max_depth`**: 5 (CV F1-score: 0.9227)
  * 選擇較小的深度 (5) 有助於防止在相對較小的下採樣資料集上發生過擬合，並期望在完整資料集上具有更好的泛化能力。

### 4.5 `class_weight` 調校

在確定了 `n_estimators` 和 `max_depth` 後，我在**完整的訓練集** (`x_train`, `y_train`) 上調校 `class_weight` 參數，以直接處理原始資料集的不平衡問題。

* **固定參數**: `random_state=RANDOM_SEED`, `n_jobs=-1`, `n_estimators=255`, `max_depth=5`
* **調校資料**: `x_train`, `y_train` (原始的、未下採樣的訓練集)
* **測試的權重**:
  * `'balanced'`
  * `{0: 1, 1: 50}`
  * `{0: 1, 1: 100}`
  * `{0: 1, 1: 200}`
  * `{0: 1, 1: 300}`
  * `{0: 1, 1: 400}`
  * `{0: 1, 1: 578}` (578 約等於 `len(nonfraud_train) / len(fraud_train)`)
* **評估方式**: 直接在測試集 (`x_test`, `y_test`) 上評估 F1-score。
  * `'balanced'` F1-score: 0.4970
  * `{0: 1, 1: 50}` F1-score: 0.8387
  * `{0: 1, 1: 100}` F1-score: 0.8247
  * ...
* **最終選定 `class_weight`**: `{0: 1, 1: 50}`，它在測試集上產生了最高的 F1-score (0.8387)。這表示給予詐騙類別 50 倍的權重時，模型在召回率和精確率之間取得了較好的平衡。

### 4.6 Random Forest 調校後結果

* **最終參數**:
  * `n_estimators`: 255
  * `max_depth`: 5
  * `class_weight`: `{0: 1, 1: 50}`
  * `random_state`: 42
  * `n_jobs`: -1
* **測試集表現 (針對詐騙類別 Class=1)**:
  * Accuracy: 0.9995
  * Precision: 0.818
  * Recall: 0.860
  * F1-score: 0.839

與基準模型相比，調校後的 Random Forest 在 F1-score 上略有下降 (0.878 -> 0.839)，精確率下降較多 (0.941 -> 0.818)，但召回率有顯著提升 (0.824 -> 0.860)。這表明模型更傾向於找出詐騙交易，但代價是誤判了一些正常交易。

## 5. 更換模型嘗試 (XGBoost)

考慮到 Random Forest 調校後 F1-score 未超過基準，且 XGBoost 在處理不平衡資料和表格型資料方面通常表現優異，我嘗試了 XGBoost 模型。

* **參數**:
  * `n_estimators`: 300 (參考 RF 調校)
  * `learning_rate`: 0.1 (常用預設值)
  * `max_depth`: 5 (參考 RF 調校)
  * `random_state`: 42
* **訓練資料**: 完整的 `x_train`, `y_train`。
* **測試集表現 (針對詐騙類別 Class=1)**:
  * Accuracy: 0.9996
  * Precision: 0.933
  * Recall: 0.824
  * F1-score: 0.875

XGBoost 在此設定下的 F1-score (0.875) 略低於初始 Random Forest (0.878)，但高於調校後的 Random Forest (0.839)。其精確率 (0.933) 較高，召回率 (0.824) 與範例相當。

## 6. 結果比較與分析

* **參數調校的影響**：
  * `n_estimators` 和 `max_depth` 的調整主要在下採樣資料集上進行，以找到合理的參數設定。
  * `class_weight` 的調整對 Random Forest 在不平衡資料上的表現至關重要。`{0:1, 1:50}` 的設定顯著提升了召回率，但犧牲了部分精確率。
* **模型比較**：
  * 調校後的 Random Forest 雖然 F1-score (0.839) 低於範例，但召回率 (0.860) 是三者中最高的，這在詐騙偵測中可能更受歡迎 (寧可錯殺一百，不可放過一個詐騙)。
  * XGBoost 的 F1-score (0.875) 非常接近範例的表現，其精確率 (0.933) 和召回率 (0.824) 也與範例相似。

## 7. 結論與未來方向

本次參數調校過程中：

1. 我首先在下採樣資料集上為 Random Forest 找到了較優的 `n_estimators=255` 和 `max_depth=5`。
2. 接著在完整訓練集上，透過調整 `class_weight`，找到了 `{0:1, 1:50}` 作為最佳權重，使得 Random Forest 模型在召回率上有較大提升，最終 F1-score 為 0.839。
3. 嘗試 XGBoost 模型，在未使用 `stratify` 進行資料分割且未針對不平衡做顯式權重調整的情況下，獲得了 0.875 的 F1-score。

**結論**：

* 初始的 Random Forest (未調校，`n_estimators=100`) 表現最好 (F1-score: 0.878)。
* XGBoost 的表現 (F1-score: 0.875) 非常接近範例。
* 調校後的 Random Forest (F1-score: 0.839) 雖然整體 F1-score 較低，但在召回率上表現最優。
