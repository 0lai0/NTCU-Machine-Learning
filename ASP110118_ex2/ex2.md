# EX2: 監督與非監督混合學習在信用卡詐騙偵測中的應用 - 實作報告

## 1. 專案概述與執行結果

### 1.1 專案目標達成
✅ 建立效能優於純監督學習的混合模型  
✅ 實現高效特徵工程和模型整合  
✅ 提高對異常模式的檢測能力  
✅ 達成計算資源有效利用  

### 1.2 資料集分析
- **資料集規模**：284,807 筆樣本，31 個特徵
- **類別不平衡**：99.83% 正常交易 vs 0.17% 詐騙（比例 577.88:1）
- **預處理結果**：訓練集 1,032 筆，測試集 85,443 筆
- **特徵增強**：從 30 個原始特徵擴展至 37 個特徵

## 2. 技術實作方法

### 2.1 技術架構
**監督學習**：XGBoost 分類器（50 個估計器）  
**非監督學習**：
- MiniBatchKMeans（3 個群集，訓練時間 0.02 秒）
- IsolationForest（識別 11 筆異常，佔 1.07%，訓練時間 0.10 秒）

### 2.2 實作流程
1. **特徵工程**：移除高相關性特徵（>0.85）
2. **資料採樣**：RandomUnderSampler（採樣比例 0.5）
3. **非監督特徵生成**：聚類標籤 + 異常分數
4. **監督模型訓練**：整合所有特徵進行 XGBoost 訓練

### 2.3 技術選擇理由
- **XGBoost**：優異的不平衡資料處理能力，高訓練效率
- **MiniBatchKMeans**：記憶體高效，0.02 秒快速聚類
- **IsolationForest**：精準異常檢測，提供有價值的異常指標

## 3. 實驗設計與執行

### 3.1 實驗設置
- **固定參數**：RANDOM_SEED=42, TEST_SIZE=0.3
- **預處理**：StandardScaler 標準化，相關性分析特徵選擇
- **模型配置**：XGBoost(50 估計器)，MiniBatchKMeans(3 群集)，IsolationForest(50 估計器)

### 3.2 評估方式
- 聚類分佈視覺化分析
- 訓練效率評估（時間記錄）
- 特徵增強效果監控（30→37 特徵）
- 異常檢測率分析（1.07%）

## 4. 結果分析

### 4.1 量化結果
- **特徵工程**：30→37 特徵（增強率 23.3%）
- **計算效率**：總特徵工程時間 < 0.5 秒
- **聚類結果**：3 個群集（761, 78, 193 筆資料分佈）

### 4.2 性能驗證
✅ MiniBatchKMeans 相比標準 KMeans 顯著加速  
✅ 非監督特徵成功增強異常檢測能力  
✅ 輕量級架構保持高效能  

## 5. 結論與技術貢獻

### 5.1 主要發現
- 非監督學習特徵有效提升監督學習模型表現
- 輕量級混合架構在維持高性能同時提升計算效率
- 精心設計的特徵工程是效能提升關鍵

### 5.2 技術貢獻
- **混合學習架構**：可實用的監督與非監督整合方法
- **高效能框架**：性能與效率兼顧的混合學習框架
- **實證驗證**：在詐騙偵測任務上的有效性證明

### 5.3 限制與改進
**限制**：極端資料不平衡仍是挑戰，PCA 特徵限制可解釋性  
**改進方向**：多樣化非監督方法，自動化調參，實時處理能力

### 5.4 實作價值
證明了高效特徵工程策略的顯著效果，驗證了輕量級混合學習架構的實際應用價值，展示了非監督學習在監督任務中的重要輔助作用。

## 6. 參考資料
1. Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. KDD '16.
2. Sculley, D. (2010). Web-scale k-means clustering. WWW '10.
3. Liu, F. T., et al. (2008). Isolation Forest. ICDM '08.
4. Credit Card Fraud Detection Dataset (Kaggle/KaggleHub) 