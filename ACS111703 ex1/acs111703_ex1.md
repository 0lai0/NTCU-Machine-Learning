# Challenge 1: Supervised vs Unsupervised Learning

## Objective
Compare Random Forest (supervised learning) and K-Means (unsupervised learning) using the same general settings to achieve results that exceed the baseline performance (Precision, Recall, F1 score).

## Dataset
- Source: Credit Card Fraud Detection Dataset from Kaggle
- Type: Binary classification problem (Fraud vs Non-Fraud)
- Features: 30 features (V1-V28 are PCA transformed, Amount, Class)
- Challenge: Highly imbalanced dataset (~0.17% fraudulent transactions)

## Methodology

### Data Preprocessing
1. Data Loading: Load creditcard fraud dataset from Kaggle Hub
2. Feature Engineering: 
   - Remove 'Time' column (not relevant for fraud detection)
   - Standardize 'Amount' feature using StandardScaler
3. Class Distribution Analysis: Analyze fraud vs non-fraud transaction ratios

### Model 1: Random Forest (Supervised Learning)
- Algorithm: RandomForestClassifier
- Parameters: 
  - n_estimators=100
  - random_state=42
- Training: Uses labeled data (both features and target class)
- Evaluation: Standard classification metrics

### Model 2: K-Means Clustering (Unsupervised Learning)
- Algorithm: K-Means clustering
- Approach: 
  - Train only on normal (non-fraud) transactions
  - Use silhouette score to find optimal number of clusters (k=2-4)
  - Apply label alignment to map clusters to fraud/non-fraud classes
- Key Innovation: Semi-supervised approach using unsupervised learning

## Results

### Dataset Analysis
```
Fraudulent:492, non-fraudulent:284315
the positive class (frauds) percentage: 0.0017304750013189597
(0.173%)
```

### Random Forest (Supervised Learning) Results
```
Random Forest Evaluation:
===============================================
         Accuracy: 0.999637185029934
 Precision Score: 0.9411764705882353
    Recall Score: 0.8235294117647058
       F1 Score: 0.8784313725490196

Classification Report:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     85307
           1       0.94      0.82      0.88       136

    accuracy                           1.00     85443
   macro avg       0.97      0.91      0.94     85443
weighted avg       1.00      1.00      1.00     85443
```

### K-Means (Unsupervised Learning) Results
```
KMeans (Unsupervised) Evaluation:
===============================================
         Accuracy: 0.999672961580501
 Precision Score: 0.9285714285714286
    Recall Score: 0.8602941176470589
       F1 Score: 0.8931297709923665

Classification Report:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     85307
           1       0.93      0.86      0.89       136

    accuracy                           1.00     85443
   macro avg       0.96      0.93      0.95     85443
weighted avg       1.00      1.00      1.00     85443
```

## Key Insights
1. Supervised Learning: Leverages labeled data for direct pattern recognition
2. Unsupervised Learning: Identifies anomalies/outliers that may represent fraud
3. Performance Trade-off: Supervised typically outperforms unsupervised, but unsupervised can detect novel fraud patterns

## Technical Implementation Notes
- Same train/test split (30% test size, random_state=42)
- Consistent preprocessing pipeline
- Robust evaluation function for fair comparison
- Label alignment technique for unsupervised predictions