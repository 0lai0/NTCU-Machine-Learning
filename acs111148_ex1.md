# 實驗一報告：監督式與非監督式詐欺偵測報告

## 實驗目的

本實驗旨在比較兩種機器學習策略──監督式學習（XGBoost）與非監督式學習（KMeans + PCA）──於信用卡詐欺資料集上的偵測效能與設計思路，探討在極度不平衡資料中，各模型的準確度、召回率與適用性。

---

## 監督式學習模型（XGBoost）

### 模型設計

* 使用 `XGBoostClassifier` 處理標記好的交易資料
* 依據 `precision >= 0.935` 為主條件篩選最佳 threshold
* 若無法達成，回退至 F1 分數最佳門檻

### 超參數：

* `n_estimators=500`
* `max_depth=4`
* `learning_rate=0.07`
* `scale_pos_weight=正負樣本比`
* `min_child_weight=2`, `gamma=0.1`, `reg_alpha=0.5`, `reg_lambda=1.2`

### 訓練流程：

* 使用 kagglehub 載入資料，標準化後拆分訓練集/測試集
* 對 `Amount` 欄位標準化，移除 `Time` 欄位
* 預測後依門檻區間（0.91 \~ 0.97）迴圈找最佳門檻值，平衡 precision 與 recall

### 最終結果

```
XGBoost Model Evaluation:
=============================================
         Accuracy: 0.9996722961506501
  Precision Score: 0.9426229508196722
     Recall Score: 0.8455882352941176
         F1 Score: 0.8914728682170543
```

---

## 非監督式學習模型（PCA + KMeans）

### 模型設計：

* 使用 `PCA` 將特徵降維保留 97% 變異量
* 基於 KMeans 分群，指定部份正常與詐欺交易作為初始中心點種子
* 執行多次 KMeans 聚類，對每筆測試資料使用眾數投票決定最終預測

### 訓練參數：

* PCA 保留主成分：97%
* KMeans 分群數量：5 群
* Ensembling 執行次數：7
* 正常種子樣本數：5000 筆
* 詐欺種子樣本數：500 筆

### 判斷方法：

* 統計每群被預測為詐欺的比率，選出 `詐欺比例最高的群集` 作為異常標記依據
* 將屬於該群的資料視為詐欺

### 最終結果

```
Tuned KMeans (k=5, PCA=0.97) Evaluation:
==================================================
         Accuracy: 0.9990
  Precision Score: 0.8351
     Recall Score: 0.5473
         F1 Score: 0.6612
```

---