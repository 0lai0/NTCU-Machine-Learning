# ex1.md

本次挑戰目標為利用同一組資料設定，應用有監督學習（Random Forest）與非監督學習（KMeans）模型進行信用卡詐騙偵測，並嘗試超越範例提供的評估指標（Precision、Recall、F1 Score）。

由於資料中詐騙交易僅佔極小比例（約 0.172%），面對高度不平衡的分類問題，選擇適當的模型與資料處理方式顯得格外重要。

---

### 實作流程

#### 1. 資料載入與前處理

* 使用 `kagglehub` 套件下載 Kaggle 上的信用卡詐騙資料集。
* 將 `Amount` 欄位標準化，移除 `Time` 欄位（與詐騙無直接關聯）。
* 將資料分為特徵 (`X`) 與標籤 (`y`)。

#### 2. 有監督學習：Random Forest

* 將資料分為訓練集與測試集（70:30）。
* 使用 `RandomForestClassifier` 模型進行訓練。
* 評估指標：Accuracy、Precision、Recall、F1 Score。

#### 3. 非監督學習：KMeans

* 從正常交易中隨機選取 1000 筆樣本作為 KMeans 的訓練資料。
* 透過 Silhouette Score 決定最佳群數（k 值）。
* 對測試集進行群集預測，並對齊群集標籤與實際標籤。
* 同樣使用上述指標進行模型評估。

---

### 成果比較

| 模型            | Accuracy | Precision | Recall | F1 Score |
| ------------- | -------- | --------- | ------ | -------- |
| Random Forest | 高        | 高         | 中      | 中上       |
| KMeans        | 中        | 低         | 低      | 低        |

> 精確數值請參考 `ex1.ipynb` 執行結果輸出。

### 

1. **Random Forest**：適用於處理高維數、類別不平衡問題，且能提供特徵重要性，屬於穩健的基準模型。

2. **KMeans**：作為一種無監督學習方法，可探索資料的內在群聚特徵，觀察是否能自行將詐騙交易與正常交易區分。

3. **取樣與標準化**：

   * 標準化金額欄位可避免模型偏向高金額。
   * 從非詐騙交易中取樣訓練 KMeans 是為了避免不平衡資料導致模型偏斜。

4. **Silhouette Score**：自動判斷最佳 k 值，減少人工設參的影響。

---

### 

* Random Forest 在詐騙偵測上表現較穩定，能捕捉到部分詐騙樣本。
* KMeans 由於缺乏標籤資訊且資料分布極度不平衡，難以有效偵測詐騙樣本。
* 未來可進一步結合兩者（如挑戰二所示），或嘗試 SMOTE、Autoencoder 等技術改善不平衡問題。

---
