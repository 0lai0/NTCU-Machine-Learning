原始資料極度不平衡，詐欺樣本只佔 0.17%。這會讓模型傾向只預測「正常交易」，很容易漏抓詐欺（recall 偏低）。為了解決這個問題，我做了以下幾項調整：1. 加上 class_weight='balanced_subsample'這讓每棵決策樹在訓練時，會特別加強對少數類別（詐欺）的學習，提升模型對詐欺的敏感度。2. 拉高決策樹深度（max_depth=25）這樣可以學到更多複雜條件，有助於辨認非典型詐欺行為。3. 增加樹的多樣性（max_features='sqrt'）讓每棵樹學到不一樣的東西，有助減少過擬合、提升整體穩定性。模型表現比較指標	調整前（Baseline）	調整後（目前最佳）Precision	0.94	0.9557 Recall	0.79	0.7941（微幅提升） F1 Score	0.86	0.8675 小結論：目前雖然 precision 有顯著提升，但 recall 和 f1-score 仍略低於預期。我認為已經接近使用純 RandomForest 的最佳效果，如要再提升，可能需要引入上採樣（SMOTE）或改用其他模型如 XGBoost 做進一步優化。