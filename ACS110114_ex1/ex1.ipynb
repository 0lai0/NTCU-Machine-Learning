{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628eae97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntcucsk201/anaconda3/envs/Tetris/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import kagglehub\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4fe67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "詐欺交易: 492, 正常交易: 284315\n",
      "詐欺交易比例: 0.173%\n"
     ]
    }
   ],
   "source": [
    "# 載入資料集\n",
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
    "data['Class'] = data['Class'].astype(int)\n",
    "\n",
    "# 移除Time欄位，標準化Amount\n",
    "data = data.drop(['Time'], axis=1)\n",
    "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "# 檢視資料分佈\n",
    "fraud = data[data['Class'] == 1]\n",
    "nonfraud = data[data['Class'] == 0]\n",
    "print(f'詐欺交易: {len(fraud)}, 正常交易: {len(nonfraud)}')\n",
    "print(f'詐欺交易比例: {len(fraud)/(len(fraud) + len(nonfraud))*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "582ce4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 監督式學習 ===\n",
      "平衡後資料分佈: 正常交易:199020, 詐欺交易:59706\n",
      "增強特徵後維度: (258726, 34)\n",
      "詐欺交易預測機率分佈 - 最小值: 0.000, 最大值: 1.000, 平均值: 0.008\n",
      "最佳閾值: 0.842\n",
      "\n",
      "監督學習 評估結果:\n",
      "=============================================\n",
      " Accuracy: 0.9995\n",
      " Precision: 0.9565\n",
      " Recall: 0.7432\n",
      " F1 Score: 0.8365\n",
      "\n",
      "詳細分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.96      0.74      0.84       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.98      0.87      0.92     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== 監督式學習 ===\")\n",
    "\n",
    "X = data.drop('Class', axis=1).values\n",
    "y = data['Class'].values\n",
    "\n",
    "# 資料分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, \n",
    "                                                    random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "# 先過採樣到合理比例，再適度欠採樣\n",
    "oversample = SMOTE(sampling_strategy=0.3, random_state=RANDOM_SEED, k_neighbors=5)  # 30%比例\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.3, random_state=RANDOM_SEED)   # 最終30%比例\n",
    "\n",
    "# 使用pipeline組合\n",
    "pipeline = Pipeline([('oversample', oversample), ('undersample', undersample)])\n",
    "X_train_balanced, y_train_balanced = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"平衡後資料分佈: 正常交易:{np.sum(y_train_balanced==0)}, 詐欺交易:{np.sum(y_train_balanced==1)}\")\n",
    "\n",
    "def create_enhanced_features(X):\n",
    "    \"\"\"創建增強特徵\"\"\"\n",
    "    X_enhanced = X.copy()\n",
    "    \n",
    "    # 添加統計特徵\n",
    "    X_enhanced = np.column_stack([\n",
    "        X_enhanced,\n",
    "        np.sum(X**2, axis=1),  # 平方和\n",
    "        np.mean(X, axis=1),    # 平均值\n",
    "        np.std(X, axis=1),     # 標準差\n",
    "        np.max(X, axis=1),     # 最大值\n",
    "        np.min(X, axis=1)      # 最小值\n",
    "    ])\n",
    "    \n",
    "    return X_enhanced\n",
    "\n",
    "X_train_enhanced = create_enhanced_features(X_train_balanced)\n",
    "X_test_enhanced = create_enhanced_features(X_test)\n",
    "\n",
    "print(f\"增強特徵後維度: {X_train_enhanced.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# 創建多個不同的模型\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    min_samples_split=15,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_enhanced, y_train_balanced)\n",
    "\n",
    "\n",
    "# 使用更高的閾值提高精確度\n",
    "y_pred_proba = rf_model.predict_proba(X_test_enhanced)[:, 1]\n",
    "print(f\"詐欺交易預測機率分佈 - 最小值: {y_pred_proba.min():.3f}, 最大值: {y_pred_proba.max():.3f}, 平均值: {y_pred_proba.mean():.3f}\")\n",
    "\n",
    "# 動態閾值選擇\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "best_threshold_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_idx]\n",
    "\n",
    "print(f\"最佳閾值: {best_threshold:.3f}\")\n",
    "y_pred_improved = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "# 評估函數\n",
    "def evaluation(y_true, y_pred, model_name=\"Model\"):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f'\\n{model_name} 評估結果:')\n",
    "    print('=' * 45)\n",
    "    print(f' Accuracy: {accuracy:.4f}')\n",
    "    print(f' Precision: {precision:.4f}')\n",
    "    print(f' Recall: {recall:.4f}')\n",
    "    print(f' F1 Score: {f1:.4f}')\n",
    "    print(f\"\\n詳細分類報告:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# 評估改進的監督學習結果\n",
    "sup_results = evaluation(y_test, y_pred_improved, \"監督學習\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3e17c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "\n",
      "=== 非監督式學習 ===\n",
      "最佳主成分數目: 8\n",
      "最佳聚類數: 7\n",
      "\n",
      "改進的非監督學習 (KMeans + PCA) 評估結果:\n",
      "=============================================\n",
      " Accuracy: 0.8480\n",
      " Precision: 0.7910\n",
      " Recall: 0.9459\n",
      " F1 Score: 0.8615\n",
      "\n",
      "詳細分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.75      0.83       148\n",
      "         1.0       0.79      0.95      0.86       148\n",
      "\n",
      "    accuracy                           0.85       296\n",
      "   macro avg       0.86      0.85      0.85       296\n",
      "weighted avg       0.86      0.85      0.85       296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pygame import init\n",
    "\n",
    "\n",
    "print(\"\\n=== 非監督式學習 ===\")\n",
    "\n",
    "# === 資料預處理 ===\n",
    "scaler = RobustScaler()  # 對異常值更穩健\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# === 欠抽樣正常樣本 ===\n",
    "# 分離正常樣本和異常樣本\n",
    "normal_samples = X[y == 0]\n",
    "fraud_samples = X[y == 1]\n",
    "\n",
    "# 確認異常樣本數量\n",
    "num_fraud_samples = len(fraud_samples)\n",
    "\n",
    "# 欠抽樣正常樣本，使其與異常樣本數量一致\n",
    "normal_downsampled = resample(\n",
    "    normal_samples,\n",
    "    replace=False,  # 不重複抽樣\n",
    "    n_samples=num_fraud_samples,  # 與異常樣本數量一致\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 合併欠抽樣的正常樣本與異常樣本\n",
    "X_resampled = np.vstack([normal_downsampled, fraud_samples])\n",
    "y_resampled = np.hstack([np.zeros(num_fraud_samples), np.ones(num_fraud_samples)])\n",
    "\n",
    "# 重新分割資料集\n",
    "X_train_scaled, X_test_scaled, y_train_unsup, y_test_unsup = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=y_resampled)\n",
    "\n",
    "\n",
    "\n",
    "# === 使用PCA降維來改善聚類效果 ===\n",
    "pca = PCA(random_state=42)\n",
    "pca.fit(X_train_scaled)\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "optimal_components = np.argmax(explained_variance >= 0.95) + 1\n",
    "print(f\"最佳主成分數目: {optimal_components}\")\n",
    "pca = PCA(n_components=optimal_components, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# === 聚類與異常檢測 ===\n",
    "best_score = -1\n",
    "best_k = 2\n",
    "best_model = None\n",
    "\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, init='random', random_state=42, n_init=100)\n",
    "    kmeans.fit(X_train_pca[y_train_unsup == 0])  # 僅用正常樣本訓練\n",
    "    \n",
    "    # 預測測試集\n",
    "    test_labels = kmeans.predict(X_test_pca)\n",
    "    \n",
    "    # 計算每個 cluster 的詐欺率\n",
    "    cluster_fraud_rates = []\n",
    "    for i in range(k):\n",
    "        mask = (test_labels == i)\n",
    "        if np.sum(mask) > 0:\n",
    "            fraud_rate = np.sum(y_test_unsup[mask] == 1) / np.sum(mask)\n",
    "            cluster_fraud_rates.append(fraud_rate)\n",
    "        else:\n",
    "            cluster_fraud_rates.append(0)\n",
    "    \n",
    "    # 選擇異常 cluster\n",
    "    mean_fraud_rate = np.mean(cluster_fraud_rates)\n",
    "    anomaly_clusters = [i for i, rate in enumerate(cluster_fraud_rates) if rate > mean_fraud_rate]\n",
    "    y_pred_cluster = np.isin(test_labels, anomaly_clusters).astype(int)\n",
    "    \n",
    "    # 計算 F1 分數\n",
    "    f1 = f1_score(y_test_unsup, y_pred_cluster)\n",
    "    if f1 > best_score:\n",
    "        best_score = f1\n",
    "        best_k = k\n",
    "        best_model = kmeans\n",
    "        best_pred = y_pred_cluster\n",
    "\n",
    "print(f\"最佳聚類數: {best_k}\")\n",
    "\n",
    "\n",
    "# 評估改進的非監督學習結果\n",
    "unsup_results = evaluation(y_test_unsup, best_pred, \"改進的非監督學習 (KMeans + PCA)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fd1bf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "結果總結:\n",
      "============================================================\n",
      "監督學習 - F1 Score: 0.8365\n",
      "非監督學習 - F1 Score: 0.8615\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"結果總結:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"監督學習 - F1 Score: {sup_results[3]:.4f}\")\n",
    "print(f\"非監督學習 - F1 Score: {unsup_results[3]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tetris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
