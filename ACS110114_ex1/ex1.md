# 挑戰一：改進監督與非監督學習方法
## 改進策略

### 監督學習改進（Random Forest）
1. **資料平衡處理**
   - 使用SMOTE（Synthetic Minority Oversampling Technique）
   - 為少數類別（詐欺交易）生成合成樣本
   - 避免簡單複製造成的過擬合

2. **超參數調優**
   - `min_samples_split=15`：節點分裂最小樣本數
   - `min_samples_leaf=10`：葉節點最小樣本數

3. **閾值調整**
   - 動態閾值優化
      - 不再使用固定閾值
      - 基於Precision-Recall曲線找到最佳F1分數對應的閾值
      - 自動平衡精確度和召回率

### 非監督學習改進（KMeans）
1. **資料預處理升級**
   - 使用RobustScaler替代StandardScaler
   - RobustScaler對異常值更穩健
   - 使用中位數和四分位距進行標準化
   - 欠抽樣正常樣本，將正常樣本隨機下採樣，使其比例更接近異常樣本

2. **特徵工程**
   - 使用PCA降維至15個主成分
   - 保留重要特徵，減少雜訊影響
   - 提高聚類效果

3. **聚類優化**
   - 擴大聚類數搜索範圍（2-10）
   - 使用更智能的異常檢測策略
   - 根據每個cluster的詐欺率選擇異常cluster

## 預期改進效果

### 監督學習
- **Precision**：透過閾值調整和類別平衡，預期提升
- **Recall**：SMOTE和較低閾值應能顯著提升召回率
- **F1 Score**：在精確度和召回率平衡下，整體F1分數提升

### 非監督學習
- **穩定性**：更多訓練資料和PCA降維提升聚類穩定性
- **Precision**：RobustScaler和智能cluster選擇提升檢測準確性
- **Recall**：更好的特徵表示有助於發現隱藏的詐欺模式

## 技術亮點
1. **不平衡資料處理**：SMOTE合成少數樣本
2. **特徵工程**：PCA降維和RobustScaler標準化
3. **模型優化**：ExtraTrees和超參數調優
4. **閾值調整**：針對詐欺檢測場景的特殊調整
5. **智能聚類**：基於詐欺率的cluster選擇策略