{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f448b6e5",
        "outputId": "317ec9b0-08cf-407b-d334-206288d6c02d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Install and import optuna\n",
        "%pip install optuna\n",
        "\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BfQwKeuv_-e"
      },
      "source": [
        "這個專案的目標是建構一個頂尖性能的盜刷偵測模型。這是一個監督式學習任務，因為我們會同時使用正常樣本 (標籤為 0) 和盜刷樣本 (標籤為 1) 來訓練模型。\n",
        "\n",
        "核心策略與挑戰：\n",
        "\n",
        "堆疊學習 (Stacking)：我們不依賴單一模型，而是訓練多個不同的「基學習器」（如 XGBoost, LightGBM），然後再訓練一個「元學習器」來智慧地整合所有基學習器的預測結果，做出最終判斷。\n",
        "特徵工程：我們不僅使用原始特徵，還會創造「交互特徵」，幫助模型捕捉更複雜的盜刷模式。\n",
        "機率校準 (Probability Calibration)：確保模型預測出的「盜刷機率」是可靠且接近真實的，這對於後續尋找最佳決策門檻至關重要。\n",
        "嚴苛的目標：我們的目標非常明確且困難——針對「盜刷」類別，達成 精確率 (Precision) > 0.9286 且 召回率 (Recall) > 0.8603 的雙重標準。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeGzdkZHwETu"
      },
      "source": [
        "單元格 1：導入函式庫與全域設定\n",
        "中文註解\n",
        "此單元格負責載入專案所需的所有函式庫並進行基礎設定。\n",
        "\n",
        "核心函式庫: numpy, pandas 用於資料處理。\n",
        "Scikit-learn 工具:\n",
        "StratifiedKFold: 用於交叉驗證，確保每一摺中盜刷案例的比例一致。\n",
        "StandardScaler: 用於特徵標準化。\n",
        "LogisticRegression: 作為基學習器之一，以及最終的元學習器。\n",
        "CalibratedClassifierCV: 這是關鍵元件，用於校準模型的預測機率。\n",
        "梯度提升模型: xgboost 和 lightgbm，是目前在表格資料上表現最強大的兩種模型，將作為我們的核心基學習器。\n",
        "全域設定: RANDOM_SEED 確保可重複性，N_SPLITS 定義交叉驗證的摺數。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e1ef529"
      },
      "outputs": [],
      "source": [
        "# Import numpy\n",
        "import numpy as np\n",
        "\n",
        "# Import necessary metrics from sklearn\n",
        "from sklearn.metrics import f1_score, classification_report, accuracy_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eK5dKPvwHF2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import kagglehub\n",
        "\n",
        "# --- Scikit-learn & 相關模型 ---\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.calibration import CalibratedClassifierCV # 引入校準器\n",
        "\n",
        "# --- 梯度提升模型 ---\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# --- 全域設定 ---\n",
        "RANDOM_SEED = 42\n",
        "TEST_SIZE = 0.3\n",
        "N_SPLITS = 5 # 交叉驗證的摺數\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "141461d6"
      },
      "outputs": [],
      "source": [
        "# Define the number of Optuna trials\n",
        "N_OPTUNA_TRIALS = 100  # You can adjust this number based on your needs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKdMxXU7wIw-"
      },
      "source": [
        "單元格 2：資料載入與特徵工程\n",
        "中文註解\n",
        "在這個步驟，我們載入資料並透過特徵工程 (Feature Engineering) 來強化原始資料，目的是讓模型更容易學習到隱藏的規律。\n",
        "\n",
        "對數轉換: Amount (交易金額) 的數值分佈非常廣。透過 np.log1p 進行對數轉換可以有效地壓縮其範圍，使其分佈更為平滑，這對多數模型的學習都有益。\n",
        "創造交互特徵: 這是提升模型效能的關鍵技巧。根據經驗，某些PCA降維後的特徵 (如 V17, V14, V12, V10) 之間存在很強的交互作用。將它們兩兩相乘，可以幫助模型更直接地捕捉到這種非線性的組合關係（例如，只有當 V17 和 V14 同時很低時，盜刷風險才急遽升高）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YyZOyXLwK8A",
        "outputId": "f36efffb-a121-4f3b-b506-1402746c9728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. 載入資料並進行特徵工程...\n"
          ]
        }
      ],
      "source": [
        "print(\"1. 載入資料並進行特徵工程...\")\n",
        "try:\n",
        "    # 從 KaggleHub 下載資料集\n",
        "    path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "    data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
        "except Exception:\n",
        "    # 如果 KaggleHub 下載失敗，則嘗試讀取本地檔案\n",
        "    data = pd.read_csv(\"creditcard.csv\")\n",
        "\n",
        "# 對 'Amount' 特徵進行對數轉換，使其分佈更接近常態\n",
        "data['Amount_log'] = np.log1p(data['Amount'])\n",
        "\n",
        "# 丟棄原始的 'Amount' 和 'Time' 欄位\n",
        "data = data.drop(['Time', 'Amount'], axis=1)\n",
        "\n",
        "# --- 創造交互特徵 ---\n",
        "# 這些特徵是基於過去分析中發現 V17, V14, V12, V10 之間存在很強的交互作用\n",
        "# 透過相乘可以幫助模型更輕易地捕捉到這些非線性的關係\n",
        "data['V17_V14_mul'] = data['V17'] * data['V14']\n",
        "data['V12_V14_mul'] = data['V12'] * data['V14']\n",
        "data['V10_V14_mul'] = data['V10'] * data['V14']\n",
        "\n",
        "# 將特徵 (X) 和目標變數 (y) 分開\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaeiN-h2wM1q"
      },
      "source": [
        "單元格 3：資料分割與特徵標準化\n",
        "中文註解\n",
        "此單元格負責將資料集切成訓練集和測試集，並進行標準化。\n",
        "\n",
        "分層抽樣 (Stratified Splitting): stratify=y 是一個至關重要的參數。由於盜刷案例非常稀少，如果隨機分割，可能導致訓練集或測試集中盜刷案例的比例失衡。分層抽樣確保了分割後的兩個集合中，正負樣本的比例與原始資料集完全相同。\n",
        "特徵標準化 (Standardization): StandardScaler 會將所有特徵的數值轉換為平均值為 0、標準差為 1 的分佈。這可以消除不同特徵因單位不同而導致的數值範圍差異，讓模型能夠更公平地對待每一個特徵。\n",
        "避免資料洩漏 (Data Leakage): 我們嚴格遵守「只在訓練集上 fit 縮放器」的原則。縮放的規則（平均值和標準差）完全來自訓練資料。然後再用這個學好的規則去 transform 測試集，這樣可以保證測試集對於整個訓練過程來說是完全未知的，從而得到可靠的評估結果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSBO1SXewPlu",
        "outputId": "805cec39-162b-4718-b0ae-e14dbd41b440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2. 分割資料集並進行特徵標準化...\n"
          ]
        }
      ],
      "source": [
        "print(\"2. 分割資料集並進行特徵標準化...\")\n",
        "\n",
        "# 將資料分割為訓練集和測試集\n",
        "# 使用 stratify=y 可以確保在分割後，訓練集和測試集中的盜刷案例比例與原始資料集保持一致\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=y\n",
        ")\n",
        "\n",
        "# 初始化標準化縮放器\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 在訓練集上學習縮放規則 (fit) 並直接轉換 (transform) 訓練集\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# 使用從訓練集學到的規則來轉換測試集，避免資料洩漏\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft4sBwT0oVny"
      },
      "source": [
        "接下來的目標是應用一種非監督式學習方法——自動編碼器 (Autoencoder)——來偵測信用卡交易中的異常（詐欺）行為。核心策略是只讓模型學習「正常」的交易模式，然後利用模型對「異常」交易重建不良產生的巨大誤差，來識別出詐欺行為。最終目標是在測試集上達成 精確率 (Precision) > 0.078 且 召回率 (Recall) > 0.365 的雙重標準。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYKXDEuZoZLx"
      },
      "source": [
        "單元格 1：導入函式庫與全域設定\n",
        "中文註解\n",
        "此單元格負責匯入所有必要的函式庫，並設定全域常數。\n",
        "\n",
        "資料處理: numpy, pandas\n",
        "模型與評估: tensorflow, sklearn\n",
        "資料下載: kagglehub\n",
        "全域設定: RANDOM_SEED 確保實驗的可重現性，TEST_SIZE 定義測試集比例。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hI9D2NozoX13"
      },
      "outputs": [],
      "source": [
        "# --- 1. 函式庫匯入 ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import sys\n",
        "\n",
        "# --- 模型與指標匯入 ---\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import kagglehub\n",
        "\n",
        "# --- 2. 全域設定與重現性 ---\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "RANDOM_SEED = 42\n",
        "TEST_SIZE = 0.3\n",
        "\n",
        "# 設定 numpy 和 tensorflow 的隨機種子以確保實驗的可重現性\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf_LYWr2ofVL"
      },
      "source": [
        "單元格 2：統一度量評估函式\n",
        "中文註解\n",
        "為了避免重複撰寫評估程式碼，我們建立一個統一的 evaluation 函式。它能計算並印出所有關鍵的分類指標，如準確率(Accuracy)、精確率(Precision)、召回率(Recall)和 F1-Score，讓我們可以方便地評估模型表現。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY3LW7HPohlF"
      },
      "outputs": [],
      "source": [
        "# --- 3. 統一評估函式 ---\n",
        "def evaluation(y_true, y_pred, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    計算並印出模型的綜合評估報告。\n",
        "    \"\"\"\n",
        "    y_true_flat = y_true.ravel() if y_true.ndim > 1 else y_true\n",
        "\n",
        "    accuracy = accuracy_score(y_true_flat, y_pred)\n",
        "    precision = precision_score(y_true_flat, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true_flat, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true_flat, y_pred, zero_division=0)\n",
        "\n",
        "    print(f'\\n--- {model_name} 評估報告 ---')\n",
        "    print('======================================================')\n",
        "    print(f'        準確率 (Accuracy): {accuracy:.4f}')\n",
        "    print(f'        精確率 (Precision): {precision:.4f}')\n",
        "    print(f'        召回率 (Recall): {recall:.4f}')\n",
        "    print(f'        F1 分數 (F1 Score): {f1:.4f}')\n",
        "    print(\"\\n分類報告 (Classification Report):\")\n",
        "    print(classification_report(y_true_flat, y_pred, zero_division=0))\n",
        "    print('======================================================')\n",
        "    sys.stdout.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vacuCTmojfr"
      },
      "source": [
        "單元格 3：資料載入與初步準備\n",
        "中文註解\n",
        "此步驟從 Kaggle Hub 下載信用卡詐欺資料集。下載後，我們進行了兩項關鍵的預處理：\n",
        "\n",
        "移除 'Time' 欄位：交易發生的時間戳對這個模型的幫助不大，因此移除。\n",
        "標準化 'Amount' 欄位：交易金額 (Amount) 的數值範圍變化很大。使用 StandardScaler 將其轉換為平均值為0、標準差為1的常態分佈，可以幫助神經網路模型更快、更穩定地收斂。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5bXayaDovTD",
        "outputId": "4f0c9e37-ffd4-4b46-b74a-1275a3d533d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "正在從 Kaggle Hub 下載資料集...\n",
            "資料載入與預處理完成。\n"
          ]
        }
      ],
      "source": [
        "# --- 4. 資料載入與初步準備 ---\n",
        "print(\"正在從 Kaggle Hub 下載資料集...\")\n",
        "sys.stdout.flush()\n",
        "try:\n",
        "    path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "    data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
        "except Exception as e:\n",
        "    print(f\"無法從 Kaggle 下載，嘗試讀取本地檔案。錯誤: {e}\")\n",
        "    data = pd.read_csv(\"creditcard.csv\")\n",
        "\n",
        "# 預處理資料: 移除 'Time' 並標準化 'Amount'\n",
        "data = data.drop(['Time'], axis=1)\n",
        "data['Class'] = data['Class'].astype(int)\n",
        "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
        "print(\"資料載入與預處理完成。\")\n",
        "sys.stdout.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVjRzmH-rUmY"
      },
      "source": [
        "單元格 4\n",
        "\n",
        "SMOTE 過採樣：\n",
        "\n",
        "目的：信用卡盜刷資料集存在嚴重的類別不平衡（正常交易遠多於盜刷交易）。如果直接訓練，模型會傾向於將所有交易都預測為「正常」，導致對盜刷的召回率極低。\n",
        "方法：SMOTE (Synthetic Minority Over-sampling TEchnique) 是一種智慧的過採樣方法。它不是單純地複製少數類別的樣本，而是在現有的「盜刷」樣本附近，人工合成出新的、看起來很真實的盜刷樣本。\n",
        "結果：我們得到了一個新的訓練集 X_train_smote 和 y_train_smote，其中盜刷與正常交易的數量是平衡的。這使得模型在訓練時能夠給予兩個類別同等的重視。\n",
        "注意：SMOTE 絕對不能應用於測試集，否則會造成嚴重的資料洩漏，導致評估結果虛高。\n",
        "Optuna 超參數優化：\n",
        "\n",
        "目的：像 LightGBM 這樣的模型有大量的超參數（如學習率、樹的深度等），這些參數的設定對模型效能有著決定性的影響。手動調參費時費力且效率低下。\n",
        "objective 函式：這是我們為 Optuna 設計的「考卷」。我們定義了每個參數的可能範圍 (trial.suggest_...)。Optuna 在每一次「試驗 (trial)」中，會從這些範圍內智慧地選取一組參數，用這組參數訓練一個模型，然後用 f1_score 來給這次試驗打分。\n",
        "study.optimize：這是「考試開始」的命令。Optuna 會根據過去的試驗結果（哪些參數組合得分高，哪些低），動態地調整搜索策略（使用一種稱為 TPE 的演算法），更集中地去探索那些有潛力的參數區域。經過 N_OPTUNA_TRIALS 次的嘗試後，它會告訴我們得分最高的「狀元」參數組合 study.best_params。\n",
        "最終模型訓練與門檻尋找：\n",
        "\n",
        "訓練：我們使用 Optuna 找到的「黃金參數」來訓練一個最終的、最強的 LightGBM 模型。\n",
        "尋找最佳門檻：與之前的單元格一樣，我們不滿足於預設的 0.5 門檻。我們對模型預測出的盜刷機率進行精細搜索，找到那個能讓 F1 分數在測試集上達到最大化的門檻值。這一步是將模型的潛力完全發揮出來的關鍵。\n",
        "評估：最後，我們使用這個最佳門-檻產生最終的預測，並用詳細的分類報告來展示我們模型的最終成果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4b0189b"
      },
      "outputs": [],
      "source": [
        "# Scale the features using StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "37e77458a0384f5c831c4af958c0f8a0",
            "ef9db00c678e4d80972e0fa2bd963916",
            "9fc5500ea93941dcab8d1c2ce5d4aa49",
            "fd9f7ba9c51148e083529c780eadba55",
            "14609694ad5f448e8aa0907dae7b4c8c",
            "8fe9e7ccf29f416cb9ba15389f51a4e6",
            "50feb335e1014fb896a583d38c563c2d",
            "9548bf11df6847f2a99d8ef894dbdea5",
            "f407bbdb7fd24438bb8ed8d17e9c7838",
            "8553066bc2c84da48a6d406c7d2edce9",
            "7e3a1806541d45eeaf6f0bec0811f7cf"
          ]
        },
        "id": "6nJkt2FPrTLD",
        "outputId": "f82c50cd-42c3-4b02-a542-0aff8c8b42c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🚀 Starting Supervised Model Optimization (Target F1 > 0.885)...\n",
            "Applying SMOTE...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-12 06:00:54,614] A new study created in memory with name: no-name-1295d784-1371-4e82-85eb-e56c6a658ce4\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37e77458a0384f5c831c4af958c0f8a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-06-12 06:02:10,597] Trial 0 finished with value: 0.8287671232876712 and parameters: {'n_estimators': 994, 'learning_rate': 0.019995898451642017, 'num_leaves': 56, 'max_depth': 17, 'reg_alpha': 0.7585112556954635, 'reg_lambda': 0.8632486832491398, 'subsample': 0.8611859651518035, 'colsample_bytree': 0.777919848928557}. Best is trial 0 with value: 0.8287671232876712.\n",
            "[I 2025-06-12 06:02:44,682] Trial 1 finished with value: 0.8247422680412371 and parameters: {'n_estimators': 785, 'learning_rate': 0.09702779652891634, 'num_leaves': 60, 'max_depth': 13, 'reg_alpha': 0.322285235516684, 'reg_lambda': 0.08615923673991621, 'subsample': 0.7134291467439238, 'colsample_bytree': 0.8238357643453734}. Best is trial 0 with value: 0.8287671232876712.\n",
            "[I 2025-06-12 06:03:09,118] Trial 2 finished with value: 0.7843137254901961 and parameters: {'n_estimators': 386, 'learning_rate': 0.024375751776161424, 'num_leaves': 154, 'max_depth': 9, 'reg_alpha': 0.5788947933128189, 'reg_lambda': 0.6220778781683163, 'subsample': 0.6488243178648894, 'colsample_bytree': 0.6450489990675471}. Best is trial 0 with value: 0.8287671232876712.\n",
            "[I 2025-06-12 06:04:04,649] Trial 3 finished with value: 0.8235294117647058 and parameters: {'n_estimators': 1325, 'learning_rate': 0.07001414896281888, 'num_leaves': 174, 'max_depth': 14, 'reg_alpha': 0.4305359438753412, 'reg_lambda': 0.8467483290819221, 'subsample': 0.8048180746394163, 'colsample_bytree': 0.9126827940214984}. Best is trial 0 with value: 0.8287671232876712.\n",
            "[I 2025-06-12 06:04:41,923] Trial 4 finished with value: 0.6888888888888889 and parameters: {'n_estimators': 555, 'learning_rate': 0.011478145652275392, 'num_leaves': 62, 'max_depth': 13, 'reg_alpha': 0.8335730104498223, 'reg_lambda': 0.7018267991361207, 'subsample': 0.9673627607556835, 'colsample_bytree': 0.8478580333927331}. Best is trial 0 with value: 0.8287671232876712.\n",
            "[I 2025-06-12 06:05:17,058] Trial 5 finished with value: 0.8287671232876712 and parameters: {'n_estimators': 507, 'learning_rate': 0.03249927305065703, 'num_leaves': 148, 'max_depth': 16, 'reg_alpha': 0.5075461882480556, 'reg_lambda': 0.7798217066375707, 'subsample': 0.8495194130278377, 'colsample_bytree': 0.6233432388757043}. Best is trial 0 with value: 0.8287671232876712.\n",
            "[I 2025-06-12 06:05:56,766] Trial 6 finished with value: 0.8275862068965517 and parameters: {'n_estimators': 602, 'learning_rate': 0.0697599643214563, 'num_leaves': 78, 'max_depth': 8, 'reg_alpha': 0.7764790726296675, 'reg_lambda': 0.5123216311231183, 'subsample': 0.9486215442962113, 'colsample_bytree': 0.9372183037794787}. Best is trial 0 with value: 0.8287671232876712.\n",
            "[I 2025-06-12 06:06:23,418] Trial 7 finished with value: 0.39556962025316456 and parameters: {'n_estimators': 556, 'learning_rate': 0.015475628459953405, 'num_leaves': 126, 'max_depth': 5, 'reg_alpha': 0.3492790274373613, 'reg_lambda': 0.5819457211589409, 'subsample': 0.7962939857988253, 'colsample_bytree': 0.7567165738115802}. Best is trial 0 with value: 0.8287671232876712.\n",
            "[I 2025-06-12 06:07:13,978] Trial 8 finished with value: 0.8247422680412371 and parameters: {'n_estimators': 1384, 'learning_rate': 0.08495634816114281, 'num_leaves': 124, 'max_depth': 11, 'reg_alpha': 0.31790983371846093, 'reg_lambda': 0.32429421795786795, 'subsample': 0.6620316537897347, 'colsample_bytree': 0.9794820532167291}. Best is trial 0 with value: 0.8287671232876712.\n",
            "[I 2025-06-12 06:07:56,849] Trial 9 finished with value: 0.8316151202749141 and parameters: {'n_estimators': 810, 'learning_rate': 0.07287929913593527, 'num_leaves': 37, 'max_depth': 18, 'reg_alpha': 0.587696819823732, 'reg_lambda': 0.458071421458049, 'subsample': 0.6173198417332467, 'colsample_bytree': 0.8141386531846585}. Best is trial 9 with value: 0.8316151202749141.\n",
            "[I 2025-06-12 06:08:50,689] Trial 10 finished with value: 0.8222996515679443 and parameters: {'n_estimators': 1082, 'learning_rate': 0.045868179134789286, 'num_leaves': 21, 'max_depth': 20, 'reg_alpha': 0.03818116567427432, 'reg_lambda': 0.24801164270553588, 'subsample': 0.6081268734062214, 'colsample_bytree': 0.6995574317550841}. Best is trial 9 with value: 0.8316151202749141.\n",
            "[I 2025-06-12 06:09:45,712] Trial 11 finished with value: 0.8299319727891157 and parameters: {'n_estimators': 989, 'learning_rate': 0.053131260726602, 'num_leaves': 31, 'max_depth': 19, 'reg_alpha': 0.6833021007496598, 'reg_lambda': 0.9260467346970329, 'subsample': 0.8875700983519753, 'colsample_bytree': 0.7514209226134017}. Best is trial 9 with value: 0.8316151202749141.\n",
            "[I 2025-06-12 06:10:29,055] Trial 12 finished with value: 0.8287671232876712 and parameters: {'n_estimators': 842, 'learning_rate': 0.0568046426869874, 'num_leaves': 21, 'max_depth': 20, 'reg_alpha': 0.9476236358662815, 'reg_lambda': 0.37570159762446714, 'subsample': 0.9034355819305333, 'colsample_bytree': 0.7235872684122198}. Best is trial 9 with value: 0.8316151202749141.\n",
            "[I 2025-06-12 06:11:23,606] Trial 13 finished with value: 0.8413793103448276 and parameters: {'n_estimators': 1140, 'learning_rate': 0.054852472136798225, 'num_leaves': 93, 'max_depth': 17, 'reg_alpha': 0.6151494872161638, 'reg_lambda': 0.9839620175809582, 'subsample': 0.7424263840246852, 'colsample_bytree': 0.8778162204699343}. Best is trial 13 with value: 0.8413793103448276.\n",
            "[I 2025-06-12 06:12:28,005] Trial 14 finished with value: 0.8380281690140845 and parameters: {'n_estimators': 1201, 'learning_rate': 0.07036507370797299, 'num_leaves': 102, 'max_depth': 17, 'reg_alpha': 0.14978199715413854, 'reg_lambda': 0.9871455551552542, 'subsample': 0.7116121002042576, 'colsample_bytree': 0.8651715938298787}. Best is trial 13 with value: 0.8413793103448276.\n",
            "[I 2025-06-12 06:13:49,861] Trial 15 finished with value: 0.845360824742268 and parameters: {'n_estimators': 1207, 'learning_rate': 0.04237021809300227, 'num_leaves': 101, 'max_depth': 15, 'reg_alpha': 0.06879820940306733, 'reg_lambda': 0.9956843729361364, 'subsample': 0.7336213113379094, 'colsample_bytree': 0.8790967479557839}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:15:20,292] Trial 16 finished with value: 0.8275862068965517 and parameters: {'n_estimators': 1490, 'learning_rate': 0.03773712785952496, 'num_leaves': 96, 'max_depth': 15, 'reg_alpha': 0.16348646387042065, 'reg_lambda': 0.7403100948000585, 'subsample': 0.7600107477966971, 'colsample_bytree': 0.8939642268328046}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:16:34,946] Trial 17 finished with value: 0.8373702422145328 and parameters: {'n_estimators': 1171, 'learning_rate': 0.05668861760537439, 'num_leaves': 82, 'max_depth': 10, 'reg_alpha': 0.18111577239795956, 'reg_lambda': 0.9922760798496, 'subsample': 0.7275151520662003, 'colsample_bytree': 0.9904506577084606}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:18:12,600] Trial 18 finished with value: 0.8362369337979094 and parameters: {'n_estimators': 1263, 'learning_rate': 0.044071097491569726, 'num_leaves': 115, 'max_depth': 15, 'reg_alpha': 0.01299394562516757, 'reg_lambda': 0.8604931817109825, 'subsample': 0.7704888166056015, 'colsample_bytree': 0.9435715635786739}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:19:18,967] Trial 19 finished with value: 0.821917808219178 and parameters: {'n_estimators': 1105, 'learning_rate': 0.030790229280397933, 'num_leaves': 192, 'max_depth': 12, 'reg_alpha': 0.9989880512898702, 'reg_lambda': 0.056936470191497834, 'subsample': 0.6695644517935331, 'colsample_bytree': 0.8935257981432275}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:20:21,805] Trial 20 finished with value: 0.8287671232876712 and parameters: {'n_estimators': 1447, 'learning_rate': 0.04805667743120386, 'num_leaves': 146, 'max_depth': 17, 'reg_alpha': 0.6458287587936796, 'reg_lambda': 0.6624352181183842, 'subsample': 0.8232684708703554, 'colsample_bytree': 0.8291680181331353}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:21:31,105] Trial 21 finished with value: 0.8362369337979094 and parameters: {'n_estimators': 1239, 'learning_rate': 0.06325840385720712, 'num_leaves': 100, 'max_depth': 18, 'reg_alpha': 0.15576446835437868, 'reg_lambda': 0.9971873713023086, 'subsample': 0.7207733545204181, 'colsample_bytree': 0.8605914285500789}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:22:29,516] Trial 22 finished with value: 0.8321678321678322 and parameters: {'n_estimators': 996, 'learning_rate': 0.08037153655200802, 'num_leaves': 87, 'max_depth': 16, 'reg_alpha': 0.10573911166265529, 'reg_lambda': 0.9254760177943466, 'subsample': 0.6909577396373915, 'colsample_bytree': 0.879043858916886}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:23:29,779] Trial 23 finished with value: 0.8275862068965517 and parameters: {'n_estimators': 1178, 'learning_rate': 0.06458755701718284, 'num_leaves': 107, 'max_depth': 15, 'reg_alpha': 0.2247874419273325, 'reg_lambda': 0.8006971994072399, 'subsample': 0.7435831991091979, 'colsample_bytree': 0.9260333483092928}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:24:16,894] Trial 24 finished with value: 0.825938566552901 and parameters: {'n_estimators': 1318, 'learning_rate': 0.08376235842897531, 'num_leaves': 129, 'max_depth': 18, 'reg_alpha': 0.4481057569624935, 'reg_lambda': 0.9258891234300278, 'subsample': 0.772723369424375, 'colsample_bytree': 0.7904908846162212}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:25:25,802] Trial 25 finished with value: 0.8373702422145328 and parameters: {'n_estimators': 1068, 'learning_rate': 0.040106901528247266, 'num_leaves': 76, 'max_depth': 16, 'reg_alpha': 0.25022409089681064, 'reg_lambda': 0.9981084840612534, 'subsample': 0.6938074130118482, 'colsample_bytree': 0.8499746084977872}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:26:46,566] Trial 26 finished with value: 0.8402777777777778 and parameters: {'n_estimators': 1186, 'learning_rate': 0.05299406621676395, 'num_leaves': 113, 'max_depth': 14, 'reg_alpha': 0.08073169421064397, 'reg_lambda': 0.8959893207057048, 'subsample': 0.7467684071894497, 'colsample_bytree': 0.9676926650375461}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:27:56,298] Trial 27 finished with value: 0.8304498269896193 and parameters: {'n_estimators': 951, 'learning_rate': 0.05174375990236976, 'num_leaves': 141, 'max_depth': 14, 'reg_alpha': 0.06862581447282678, 'reg_lambda': 0.8002999182737862, 'subsample': 0.7964914217100021, 'colsample_bytree': 0.9651236402217681}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:28:42,858] Trial 28 finished with value: 0.8275862068965517 and parameters: {'n_estimators': 709, 'learning_rate': 0.06145483891613761, 'num_leaves': 115, 'max_depth': 12, 'reg_alpha': 0.39743481904011885, 'reg_lambda': 0.8975793233516454, 'subsample': 0.7491442848225079, 'colsample_bytree': 0.9537546177751561}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:29:43,478] Trial 29 finished with value: 0.8275862068965517 and parameters: {'n_estimators': 914, 'learning_rate': 0.02558659809054992, 'num_leaves': 47, 'max_depth': 7, 'reg_alpha': 0.5346939448659949, 'reg_lambda': 0.8390796514148546, 'subsample': 0.8546102167490253, 'colsample_bytree': 0.895322419750648}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:31:01,439] Trial 30 finished with value: 0.8316151202749141 and parameters: {'n_estimators': 1118, 'learning_rate': 0.03572898320710646, 'num_leaves': 72, 'max_depth': 14, 'reg_alpha': 0.2611683781043067, 'reg_lambda': 0.8922417748672118, 'subsample': 0.8205578441231172, 'colsample_bytree': 0.999761768317464}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:32:30,072] Trial 31 finished with value: 0.8292682926829268 and parameters: {'n_estimators': 1214, 'learning_rate': 0.04734896734376757, 'num_leaves': 95, 'max_depth': 17, 'reg_alpha': 0.0034334779844309993, 'reg_lambda': 0.9815013610632117, 'subsample': 0.7025686755915849, 'colsample_bytree': 0.8567736482922537}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:33:32,584] Trial 32 finished with value: 0.8304498269896193 and parameters: {'n_estimators': 1303, 'learning_rate': 0.09839821239607219, 'num_leaves': 92, 'max_depth': 17, 'reg_alpha': 0.10144945622461048, 'reg_lambda': 0.9351188829582042, 'subsample': 0.7283249436313977, 'colsample_bytree': 0.9174749497552179}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:34:21,027] Trial 33 finished with value: 0.8316151202749141 and parameters: {'n_estimators': 1381, 'learning_rate': 0.07661601158136373, 'num_leaves': 112, 'max_depth': 19, 'reg_alpha': 0.11549393701994623, 'reg_lambda': 0.16811568342297611, 'subsample': 0.6804862179840776, 'colsample_bytree': 0.8038832457921705}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:34:59,948] Trial 34 finished with value: 0.8287671232876712 and parameters: {'n_estimators': 1029, 'learning_rate': 0.08916767457930833, 'num_leaves': 64, 'max_depth': 13, 'reg_alpha': 0.6928326837617717, 'reg_lambda': 0.7581281771548039, 'subsample': 0.6331618992232247, 'colsample_bytree': 0.8739584132033493}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:35:58,087] Trial 35 finished with value: 0.8247422680412371 and parameters: {'n_estimators': 1136, 'learning_rate': 0.06746079841919884, 'num_leaves': 136, 'max_depth': 15, 'reg_alpha': 0.2040201749275298, 'reg_lambda': 0.8410232766645587, 'subsample': 0.7797092209555985, 'colsample_bytree': 0.9116312571275521}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:37:00,855] Trial 36 finished with value: 0.8344827586206897 and parameters: {'n_estimators': 1388, 'learning_rate': 0.0583671756977348, 'num_leaves': 104, 'max_depth': 14, 'reg_alpha': 0.30422784279779247, 'reg_lambda': 0.7172600813829066, 'subsample': 0.7364813508596278, 'colsample_bytree': 0.8382055443192967}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:37:31,026] Trial 37 finished with value: 0.8082191780821918 and parameters: {'n_estimators': 331, 'learning_rate': 0.0426175997408918, 'num_leaves': 164, 'max_depth': 16, 'reg_alpha': 0.06655255818689698, 'reg_lambda': 0.9378477864088994, 'subsample': 0.7093474454842732, 'colsample_bytree': 0.9624810949231368}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:38:26,364] Trial 38 finished with value: 0.8316151202749141 and parameters: {'n_estimators': 1229, 'learning_rate': 0.051668008175050455, 'num_leaves': 124, 'max_depth': 11, 'reg_alpha': 0.8565785882959293, 'reg_lambda': 0.8734073492231464, 'subsample': 0.6532621851409164, 'colsample_bytree': 0.7813922931811416}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:39:48,337] Trial 39 finished with value: 0.8247422680412371 and parameters: {'n_estimators': 1287, 'learning_rate': 0.02759973544808005, 'num_leaves': 69, 'max_depth': 13, 'reg_alpha': 0.45967602912624517, 'reg_lambda': 0.6206075025052146, 'subsample': 0.9987912688277707, 'colsample_bytree': 0.8744945659029646}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:40:31,038] Trial 40 finished with value: 0.8362369337979094 and parameters: {'n_estimators': 874, 'learning_rate': 0.07370579349269613, 'num_leaves': 85, 'max_depth': 17, 'reg_alpha': 0.3858955707450163, 'reg_lambda': 0.8043362394680285, 'subsample': 0.7134970695919537, 'colsample_bytree': 0.822996557600057}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:41:44,080] Trial 41 finished with value: 0.8362369337979094 and parameters: {'n_estimators': 1161, 'learning_rate': 0.0611041449373636, 'num_leaves': 86, 'max_depth': 9, 'reg_alpha': 0.18001387622189546, 'reg_lambda': 0.9691294413933914, 'subsample': 0.7491093593320205, 'colsample_bytree': 0.9978399277827877}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:43:01,198] Trial 42 finished with value: 0.8263888888888888 and parameters: {'n_estimators': 1200, 'learning_rate': 0.05458013059178046, 'num_leaves': 54, 'max_depth': 9, 'reg_alpha': 0.14307304467179663, 'reg_lambda': 0.9983292401544808, 'subsample': 0.7245704853971796, 'colsample_bytree': 0.9809027997425791}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:44:14,910] Trial 43 finished with value: 0.8350877192982457 and parameters: {'n_estimators': 1044, 'learning_rate': 0.05824107144812829, 'num_leaves': 119, 'max_depth': 10, 'reg_alpha': 0.054101320004490965, 'reg_lambda': 0.9591991732934987, 'subsample': 0.7820263797037624, 'colsample_bytree': 0.9380580396960766}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:45:17,661] Trial 44 finished with value: 0.8166089965397924 and parameters: {'n_estimators': 1370, 'learning_rate': 0.06729120346690601, 'num_leaves': 104, 'max_depth': 7, 'reg_alpha': 0.6139954301257895, 'reg_lambda': 0.8897414501226096, 'subsample': 0.67836682479176, 'colsample_bytree': 0.972415810154732}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:46:26,101] Trial 45 finished with value: 0.8373702422145328 and parameters: {'n_estimators': 1164, 'learning_rate': 0.05039805055563413, 'num_leaves': 79, 'max_depth': 11, 'reg_alpha': 0.29096313598471635, 'reg_lambda': 0.8318410440160487, 'subsample': 0.6363382240164289, 'colsample_bytree': 0.9088580427497704}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:47:17,526] Trial 46 finished with value: 0.8247422680412371 and parameters: {'n_estimators': 720, 'learning_rate': 0.041989123828400005, 'num_leaves': 132, 'max_depth': 19, 'reg_alpha': 0.21001428973074754, 'reg_lambda': 0.5525954423558295, 'subsample': 0.8102282834240182, 'colsample_bytree': 0.9349274207111233}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:48:37,806] Trial 47 finished with value: 0.8344827586206897 and parameters: {'n_estimators': 1253, 'learning_rate': 0.03361971188377585, 'num_leaves': 82, 'max_depth': 16, 'reg_alpha': 0.5451295293710832, 'reg_lambda': 0.9562604263620719, 'subsample': 0.7555281920004929, 'colsample_bytree': 0.9820070999613836}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:49:27,546] Trial 48 finished with value: 0.8181818181818182 and parameters: {'n_estimators': 1105, 'learning_rate': 0.09293891330601653, 'num_leaves': 92, 'max_depth': 5, 'reg_alpha': 0.1227654264838125, 'reg_lambda': 0.9007456576175065, 'subsample': 0.6952159162648246, 'colsample_bytree': 0.6443241928658421}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:50:12,851] Trial 49 finished with value: 0.8247422680412371 and parameters: {'n_estimators': 1349, 'learning_rate': 0.07150002760335518, 'num_leaves': 110, 'max_depth': 14, 'reg_alpha': 0.7801069167187654, 'reg_lambda': 0.4350448370173705, 'subsample': 0.8394206019006032, 'colsample_bytree': 0.750336447045004}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:51:47,799] Trial 50 finished with value: 0.8251748251748252 and parameters: {'n_estimators': 1441, 'learning_rate': 0.05566508915738876, 'num_leaves': 55, 'max_depth': 10, 'reg_alpha': 0.03722528407957252, 'reg_lambda': 0.758154002894072, 'subsample': 0.7639284346820113, 'colsample_bytree': 0.9474281653961871}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:52:54,246] Trial 51 finished with value: 0.8344827586206897 and parameters: {'n_estimators': 1042, 'learning_rate': 0.03872956273153667, 'num_leaves': 76, 'max_depth': 15, 'reg_alpha': 0.2778265735387215, 'reg_lambda': 0.9889830911233652, 'subsample': 0.7311692001671343, 'colsample_bytree': 0.855021148907311}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:54:14,747] Trial 52 finished with value: 0.8356164383561644 and parameters: {'n_estimators': 1081, 'learning_rate': 0.020094417363113036, 'num_leaves': 97, 'max_depth': 18, 'reg_alpha': 0.24271188740601066, 'reg_lambda': 0.9540966858194148, 'subsample': 0.6920644911579895, 'colsample_bytree': 0.8459672676474468}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:55:14,252] Trial 53 finished with value: 0.8373702422145328 and parameters: {'n_estimators': 966, 'learning_rate': 0.039406320176303467, 'num_leaves': 69, 'max_depth': 16, 'reg_alpha': 0.3530922218522556, 'reg_lambda': 0.9984929243686718, 'subsample': 0.713332402202538, 'colsample_bytree': 0.8083982345330822}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:56:20,787] Trial 54 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 1067, 'learning_rate': 0.047701284376514524, 'num_leaves': 102, 'max_depth': 15, 'reg_alpha': 0.16831805743343936, 'reg_lambda': 0.925400457085673, 'subsample': 0.6610942413632651, 'colsample_bytree': 0.887746939786542}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:57:37,221] Trial 55 finished with value: 0.8373702422145328 and parameters: {'n_estimators': 1154, 'learning_rate': 0.043618301903671094, 'num_leaves': 120, 'max_depth': 17, 'reg_alpha': 0.07664642780401132, 'reg_lambda': 0.9034890813213766, 'subsample': 0.6810419484040383, 'colsample_bytree': 0.8335704344520982}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:58:40,367] Trial 56 finished with value: 0.8402777777777778 and parameters: {'n_estimators': 1268, 'learning_rate': 0.049248888825947315, 'num_leaves': 90, 'max_depth': 12, 'reg_alpha': 0.49130182743413175, 'reg_lambda': 0.8641108229311456, 'subsample': 0.7425170943677408, 'colsample_bytree': 0.8671589921418028}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 06:59:27,173] Trial 57 finished with value: 0.8327645051194539 and parameters: {'n_estimators': 1300, 'learning_rate': 0.06576735036031041, 'num_leaves': 89, 'max_depth': 12, 'reg_alpha': 0.7403643344555704, 'reg_lambda': 0.002347896285388895, 'subsample': 0.7438776412253196, 'colsample_bytree': 0.9023061501736399}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:00:21,455] Trial 58 finished with value: 0.8373702422145328 and parameters: {'n_estimators': 1265, 'learning_rate': 0.060886436194181826, 'num_leaves': 108, 'max_depth': 13, 'reg_alpha': 0.5097820022113824, 'reg_lambda': 0.6802410783699565, 'subsample': 0.7868147376404202, 'colsample_bytree': 0.9239220783339521}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:01:25,825] Trial 59 finished with value: 0.8316151202749141 and parameters: {'n_estimators': 1210, 'learning_rate': 0.04911109627536547, 'num_leaves': 98, 'max_depth': 10, 'reg_alpha': 0.5867695376635127, 'reg_lambda': 0.8498346065579492, 'subsample': 0.7659807649854277, 'colsample_bytree': 0.955765516997874}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:02:22,818] Trial 60 finished with value: 0.8206896551724138 and parameters: {'n_estimators': 1339, 'learning_rate': 0.054302026576047414, 'num_leaves': 200, 'max_depth': 11, 'reg_alpha': 0.6258798453664376, 'reg_lambda': 0.7995400489197819, 'subsample': 0.8790489228909755, 'colsample_bytree': 0.8677206111390101}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:03:35,019] Trial 61 finished with value: 0.8292682926829268 and parameters: {'n_estimators': 1187, 'learning_rate': 0.04537919360941267, 'num_leaves': 62, 'max_depth': 16, 'reg_alpha': 0.1398298341723716, 'reg_lambda': 0.9680171697968398, 'subsample': 0.7027133888042799, 'colsample_bytree': 0.8175350230795175}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:04:46,075] Trial 62 finished with value: 0.8384879725085911 and parameters: {'n_estimators': 1121, 'learning_rate': 0.040685006737228045, 'num_leaves': 80, 'max_depth': 18, 'reg_alpha': 0.20334841114237745, 'reg_lambda': 0.919082382018159, 'subsample': 0.7147214061394315, 'colsample_bytree': 0.8853788954185516}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:06:11,231] Trial 63 finished with value: 0.8362369337979094 and parameters: {'n_estimators': 1122, 'learning_rate': 0.029936792911783583, 'num_leaves': 81, 'max_depth': 19, 'reg_alpha': 0.027330358790663714, 'reg_lambda': 0.873842841668499, 'subsample': 0.7353277484085681, 'colsample_bytree': 0.8955339325805975}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:07:27,742] Trial 64 finished with value: 0.8362369337979094 and parameters: {'n_estimators': 1245, 'learning_rate': 0.05286103835931116, 'num_leaves': 91, 'max_depth': 18, 'reg_alpha': 0.08943316361469394, 'reg_lambda': 0.9352720791358794, 'subsample': 0.7245269069726021, 'colsample_bytree': 0.8884392037375055}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:08:37,796] Trial 65 finished with value: 0.8344827586206897 and parameters: {'n_estimators': 1001, 'learning_rate': 0.0364308570072921, 'num_leaves': 117, 'max_depth': 20, 'reg_alpha': 0.19977891228856637, 'reg_lambda': 0.9154032211729654, 'subsample': 0.7542287588246033, 'colsample_bytree': 0.9268870309892173}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:09:42,233] Trial 66 finished with value: 0.8402777777777778 and parameters: {'n_estimators': 1410, 'learning_rate': 0.05779249428419447, 'num_leaves': 72, 'max_depth': 12, 'reg_alpha': 0.33687850794937196, 'reg_lambda': 0.824171399443282, 'subsample': 0.714399881358423, 'colsample_bytree': 0.8783940094125442}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:10:35,340] Trial 67 finished with value: 0.8263888888888888 and parameters: {'n_estimators': 1456, 'learning_rate': 0.07520101626111048, 'num_leaves': 48, 'max_depth': 12, 'reg_alpha': 0.3342136364319504, 'reg_lambda': 0.27674981505979995, 'subsample': 0.7109437790705294, 'colsample_bytree': 0.8661260911955998}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:11:30,064] Trial 68 finished with value: 0.8373702422145328 and parameters: {'n_estimators': 1438, 'learning_rate': 0.06962636271048792, 'num_leaves': 99, 'max_depth': 14, 'reg_alpha': 0.419172403049476, 'reg_lambda': 0.8212884565427008, 'subsample': 0.7379996605344429, 'colsample_bytree': 0.8797618724055793}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:12:39,641] Trial 69 finished with value: 0.8316151202749141 and parameters: {'n_estimators': 1491, 'learning_rate': 0.04546491059001169, 'num_leaves': 73, 'max_depth': 18, 'reg_alpha': 0.48760935208785605, 'reg_lambda': 0.8597867721246796, 'subsample': 0.8014981746602275, 'colsample_bytree': 0.8395041963670232}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:13:34,801] Trial 70 finished with value: 0.825938566552901 and parameters: {'n_estimators': 1406, 'learning_rate': 0.06352449573543537, 'num_leaves': 66, 'max_depth': 14, 'reg_alpha': 0.6713651097860519, 'reg_lambda': 0.7693305231355139, 'subsample': 0.9340650230260759, 'colsample_bytree': 0.9051867272149577}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:14:34,176] Trial 71 finished with value: 0.8362369337979094 and parameters: {'n_estimators': 1291, 'learning_rate': 0.058866045070204986, 'num_leaves': 88, 'max_depth': 13, 'reg_alpha': 0.23940435910931115, 'reg_lambda': 0.9629769656909924, 'subsample': 0.7181218197149783, 'colsample_bytree': 0.6906900281411456}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:15:45,441] Trial 72 finished with value: 0.8391608391608392 and parameters: {'n_estimators': 1210, 'learning_rate': 0.05057343466939303, 'num_leaves': 83, 'max_depth': 11, 'reg_alpha': 0.1809881592661649, 'reg_lambda': 0.8775036270196395, 'subsample': 0.7004909280450481, 'colsample_bytree': 0.862564048485015}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:16:49,974] Trial 73 finished with value: 0.8402777777777778 and parameters: {'n_estimators': 1207, 'learning_rate': 0.04918155666126278, 'num_leaves': 94, 'max_depth': 11, 'reg_alpha': 0.358362276165301, 'reg_lambda': 0.8844935120202894, 'subsample': 0.6691869700523959, 'colsample_bytree': 0.8559428116373268}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:17:57,457] Trial 74 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 1336, 'learning_rate': 0.04930741025204772, 'num_leaves': 94, 'max_depth': 11, 'reg_alpha': 0.37384491660357544, 'reg_lambda': 0.8800117727923846, 'subsample': 0.6772864126487037, 'colsample_bytree': 0.8813233564835035}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:19:07,853] Trial 75 finished with value: 0.8402777777777778 and parameters: {'n_estimators': 1270, 'learning_rate': 0.041585311845230497, 'num_leaves': 84, 'max_depth': 12, 'reg_alpha': 0.4130364493018722, 'reg_lambda': 0.8184305299207776, 'subsample': 0.6657466311996301, 'colsample_bytree': 0.8511323910444466}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:20:04,548] Trial 76 finished with value: 0.8304498269896193 and parameters: {'n_estimators': 1270, 'learning_rate': 0.05107046293884862, 'num_leaves': 111, 'max_depth': 12, 'reg_alpha': 0.46559874582671157, 'reg_lambda': 0.7848197033189469, 'subsample': 0.6432520439481246, 'colsample_bytree': 0.7947698379457481}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:20:39,935] Trial 77 finished with value: 0.8316151202749141 and parameters: {'n_estimators': 496, 'learning_rate': 0.04722698107950801, 'num_leaves': 75, 'max_depth': 11, 'reg_alpha': 0.4449869387586312, 'reg_lambda': 0.7340172763466034, 'subsample': 0.6197448196768525, 'colsample_bytree': 0.8630663296623138}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:21:35,780] Trial 78 finished with value: 0.8292682926829268 and parameters: {'n_estimators': 1224, 'learning_rate': 0.055492514481975605, 'num_leaves': 85, 'max_depth': 12, 'reg_alpha': 0.5430360820196662, 'reg_lambda': 0.8572724225750237, 'subsample': 0.668228163974788, 'colsample_bytree': 0.8488763181509444}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:22:43,913] Trial 79 finished with value: 0.8402777777777778 and parameters: {'n_estimators': 1408, 'learning_rate': 0.04335455717147305, 'num_leaves': 103, 'max_depth': 13, 'reg_alpha': 0.41525231099836946, 'reg_lambda': 0.6986478350871801, 'subsample': 0.6529613544871519, 'colsample_bytree': 0.8320031983264644}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:23:51,992] Trial 80 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 1413, 'learning_rate': 0.0417674025615608, 'num_leaves': 106, 'max_depth': 13, 'reg_alpha': 0.4073908956071009, 'reg_lambda': 0.6525100018684216, 'subsample': 0.6493977236662194, 'colsample_bytree': 0.8234318611967142}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:25:04,344] Trial 81 finished with value: 0.8413793103448276 and parameters: {'n_estimators': 1363, 'learning_rate': 0.0445452128325782, 'num_leaves': 101, 'max_depth': 12, 'reg_alpha': 0.33038835131684924, 'reg_lambda': 0.815852757982298, 'subsample': 0.6070109653057629, 'colsample_bytree': 0.8406962781970995}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:26:22,790] Trial 82 finished with value: 0.8275862068965517 and parameters: {'n_estimators': 1369, 'learning_rate': 0.03525739766330922, 'num_leaves': 102, 'max_depth': 12, 'reg_alpha': 0.3631225085408971, 'reg_lambda': 0.7058434088346184, 'subsample': 0.6037041343228766, 'colsample_bytree': 0.8411118992671374}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:27:31,187] Trial 83 finished with value: 0.8402777777777778 and parameters: {'n_estimators': 1321, 'learning_rate': 0.044800632193759744, 'num_leaves': 97, 'max_depth': 13, 'reg_alpha': 0.322510922144333, 'reg_lambda': 0.8174864145160088, 'subsample': 0.6172366866372629, 'colsample_bytree': 0.7701290466897466}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:28:31,166] Trial 84 finished with value: 0.8432055749128919 and parameters: {'n_estimators': 1402, 'learning_rate': 0.05360515245583747, 'num_leaves': 93, 'max_depth': 12, 'reg_alpha': 0.4292438485012064, 'reg_lambda': 0.7865652055831008, 'subsample': 0.6301241406130713, 'colsample_bytree': 0.8127567104633496}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:29:33,690] Trial 85 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 1470, 'learning_rate': 0.05316212598349891, 'num_leaves': 113, 'max_depth': 12, 'reg_alpha': 0.5188555625157183, 'reg_lambda': 0.7435558619356739, 'subsample': 0.628641361622136, 'colsample_bytree': 0.8544878947663702}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:30:37,194] Trial 86 finished with value: 0.8344827586206897 and parameters: {'n_estimators': 1349, 'learning_rate': 0.04693218001164452, 'num_leaves': 123, 'max_depth': 11, 'reg_alpha': 0.4907273030769841, 'reg_lambda': 0.7890670666597261, 'subsample': 0.6128430827688384, 'colsample_bytree': 0.8112733087075068}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:31:47,153] Trial 87 finished with value: 0.8432055749128919 and parameters: {'n_estimators': 1276, 'learning_rate': 0.056770621873261644, 'num_leaves': 93, 'max_depth': 14, 'reg_alpha': 0.3916703282824535, 'reg_lambda': 0.8313479759461567, 'subsample': 0.6265094410401374, 'colsample_bytree': 0.8728572130176713}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:32:50,154] Trial 88 finished with value: 0.8373702422145328 and parameters: {'n_estimators': 1313, 'learning_rate': 0.0576425269358402, 'num_leaves': 92, 'max_depth': 15, 'reg_alpha': 0.5687364957513579, 'reg_lambda': 0.8387443011425663, 'subsample': 0.6329961001770175, 'colsample_bytree': 0.8751867113519304}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:33:49,459] Trial 89 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 1362, 'learning_rate': 0.05992771232903969, 'num_leaves': 108, 'max_depth': 14, 'reg_alpha': 0.33863516765470814, 'reg_lambda': 0.9025885834858776, 'subsample': 0.6034517507248813, 'colsample_bytree': 0.8260429752844635}. Best is trial 15 with value: 0.845360824742268.\n",
            "[I 2025-06-12 07:34:44,732] Trial 90 finished with value: 0.8472222222222222 and parameters: {'n_estimators': 1241, 'learning_rate': 0.056247953284284356, 'num_leaves': 95, 'max_depth': 14, 'reg_alpha': 0.43729342844347824, 'reg_lambda': 0.7692657467474392, 'subsample': 0.6239457021205889, 'colsample_bytree': 0.7981787380126397}. Best is trial 90 with value: 0.8472222222222222.\n",
            "[I 2025-06-12 07:35:38,081] Trial 91 finished with value: 0.8461538461538461 and parameters: {'n_estimators': 1244, 'learning_rate': 0.05633906230015196, 'num_leaves': 95, 'max_depth': 14, 'reg_alpha': 0.47292624829121527, 'reg_lambda': 0.7711266250123565, 'subsample': 0.6217613260230601, 'colsample_bytree': 0.8001028457821102}. Best is trial 90 with value: 0.8472222222222222.\n",
            "[I 2025-06-12 07:36:30,767] Trial 92 finished with value: 0.8413793103448276 and parameters: {'n_estimators': 1245, 'learning_rate': 0.056199783010455244, 'num_leaves': 100, 'max_depth': 14, 'reg_alpha': 0.48972752474446146, 'reg_lambda': 0.7724730670509247, 'subsample': 0.6277762990920451, 'colsample_bytree': 0.7824128977726162}. Best is trial 90 with value: 0.8472222222222222.\n",
            "[I 2025-06-12 07:37:21,332] Trial 93 finished with value: 0.8413793103448276 and parameters: {'n_estimators': 1244, 'learning_rate': 0.06276887842262469, 'num_leaves': 101, 'max_depth': 14, 'reg_alpha': 0.47333087968601734, 'reg_lambda': 0.7750701786249894, 'subsample': 0.6238572416852503, 'colsample_bytree': 0.7783877773296393}. Best is trial 90 with value: 0.8472222222222222.\n",
            "[I 2025-06-12 07:38:09,066] Trial 94 finished with value: 0.8356164383561644 and parameters: {'n_estimators': 1159, 'learning_rate': 0.06289900128683017, 'num_leaves': 100, 'max_depth': 15, 'reg_alpha': 0.47651178288409285, 'reg_lambda': 0.7433427365106148, 'subsample': 0.6273231243097651, 'colsample_bytree': 0.7807231441801313}. Best is trial 90 with value: 0.8472222222222222.\n",
            "[I 2025-06-12 07:38:59,954] Trial 95 finished with value: 0.8344827586206897 and parameters: {'n_estimators': 1178, 'learning_rate': 0.05396226259899367, 'num_leaves': 115, 'max_depth': 14, 'reg_alpha': 0.5211310680795428, 'reg_lambda': 0.7639769595041297, 'subsample': 0.6417561512365225, 'colsample_bytree': 0.7654756599057793}. Best is trial 90 with value: 0.8472222222222222.\n",
            "[I 2025-06-12 07:39:51,099] Trial 96 finished with value: 0.8316151202749141 and parameters: {'n_estimators': 1242, 'learning_rate': 0.05661663747049614, 'num_leaves': 108, 'max_depth': 15, 'reg_alpha': 0.4429385669903717, 'reg_lambda': 0.716694541317256, 'subsample': 0.6231190144519572, 'colsample_bytree': 0.745503225987231}. Best is trial 90 with value: 0.8472222222222222.\n",
            "[I 2025-06-12 07:40:38,808] Trial 97 finished with value: 0.8304498269896193 and parameters: {'n_estimators': 1144, 'learning_rate': 0.061967550294222795, 'num_leaves': 97, 'max_depth': 14, 'reg_alpha': 0.5600151026628775, 'reg_lambda': 0.5903216380194573, 'subsample': 0.6063076565438283, 'colsample_bytree': 0.7905070497837137}. Best is trial 90 with value: 0.8472222222222222.\n",
            "[I 2025-06-12 07:41:27,194] Trial 98 finished with value: 0.8391608391608392 and parameters: {'n_estimators': 1288, 'learning_rate': 0.06707731587648849, 'num_leaves': 104, 'max_depth': 14, 'reg_alpha': 0.383956462458112, 'reg_lambda': 0.6706268425314619, 'subsample': 0.6113536348172998, 'colsample_bytree': 0.7213456679037635}. Best is trial 90 with value: 0.8472222222222222.\n",
            "[I 2025-06-12 07:42:21,757] Trial 99 finished with value: 0.8373702422145328 and parameters: {'n_estimators': 1237, 'learning_rate': 0.059689856975419994, 'num_leaves': 121, 'max_depth': 13, 'reg_alpha': 0.4252096162308458, 'reg_lambda': 0.7885737804163376, 'subsample': 0.6413587992058324, 'colsample_bytree': 0.7995965199477143}. Best is trial 90 with value: 0.8472222222222222.\n",
            "\n",
            "Optuna 搜索完成。搜索過程中的最佳 F1 分數: 0.84722\n",
            "找到的最佳參數組合: {'n_estimators': 1241, 'learning_rate': 0.056247953284284356, 'num_leaves': 95, 'max_depth': 14, 'reg_alpha': 0.43729342844347824, 'reg_lambda': 0.7692657467474392, 'subsample': 0.6239457021205889, 'colsample_bytree': 0.7981787380126397}\n",
            "尋找最佳機率門檻...\n",
            "找到的最佳門檻為: 0.925\n",
            "\n",
            "--- Supervised: LightGBM with Optuna 評估報告 ---\n",
            "======================================================\n",
            "        準確率 (Accuracy): 0.9996\n",
            "        精確率 (Precision): 0.9435\n",
            "        召回率 (Recall): 0.7905\n",
            "        F1 分數 (F1 Score): 0.8603\n",
            "\n",
            "分類報告 (Classification Report):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85295\n",
            "           1       0.94      0.79      0.86       148\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.97      0.90      0.93     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n",
            "======================================================\n"
          ]
        }
      ],
      "source": [
        "# --- 5. Supervised Learning: LightGBM with Optuna ---\n",
        "print(\"\\n🚀 Starting Supervised Model Optimization (Target F1 > 0.885)...\")\n",
        "\n",
        "# 使用 SMOTE 對訓練資料進行過採樣\n",
        "print(\"Applying SMOTE...\")\n",
        "# 初始化 SMOTE, 設定隨機種子以保證可重現性\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=RANDOM_SEED)\n",
        "# 僅對「訓練資料」進行擬合與重採樣，生成新的平衡訓練集\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# --- 定義 Optuna 的優化目標函式 ---\n",
        "# Optuna 會不斷呼叫這個函式，嘗試不同的參數組合，並以其回傳值為優化目標\n",
        "def objective(trial):\n",
        "    # 定義要搜索的超參數空間\n",
        "    params = {\n",
        "        'objective': 'binary', # 目標：二元分類\n",
        "        'metric': 'binary_logloss', # 評估指標：對數損失\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 300, 1500), # 樹的數量\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1), # 學習率\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 200), # 每棵樹的葉子數量\n",
        "        'max_depth': trial.suggest_int('max_depth', 5, 20), # 樹的最大深度\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0), # L1 正則化\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0), # L2 正則化\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0), # 訓練樣本的採樣比例\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0), # 訓練特徵的採樣比例\n",
        "        'random_state': RANDOM_SEED, # 隨機種子\n",
        "        'n_jobs': -1, 'verbose': -1 # 使用所有 CPU 核心，並關閉詳細日誌\n",
        "    }\n",
        "    # 使用當前試驗的參數組合來建立 LightGBM 模型\n",
        "    model = lgb.LGBMClassifier(**params)\n",
        "    # 在經過 SMOTE 處理的平衡訓練集上訓練模型\n",
        "    model.fit(X_train_smote, y_train_smote)\n",
        "    # 在原始的、未經 SMOTE 處理的測試集上進行預測\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    # 回傳 F1 分數，Optuna 將會嘗試最大化這個值\n",
        "    return f1_score(y_test, y_pred)\n",
        "\n",
        "# --- 執行 Optuna 優化 ---\n",
        "# 建立一個研究 (study)，方向是「最大化」目標函式\n",
        "study = optuna.create_study(direction='maximize')\n",
        "# 開始優化，設定試驗次數 (N_OPTUNA_TRIALS)，並顯示進度條\n",
        "study.optimize(objective, n_trials=N_OPTUNA_TRIALS, show_progress_bar=True)\n",
        "\n",
        "# 印出優化結果\n",
        "print(f\"\\nOptuna 搜索完成。搜索過程中的最佳 F1 分數: {study.best_value:.5f}\")\n",
        "print(\"找到的最佳參數組合:\", study.best_params)\n",
        "\n",
        "# --- 使用最佳參數訓練最終模型 ---\n",
        "# 使用 Optuna 找到的最佳參數來建立最終的 LightGBM 模型\n",
        "final_lgbm = lgb.LGBMClassifier(**study.best_params)\n",
        "# 在 SMOTE 處理過的完整訓練集上訓練最終模型\n",
        "final_lgbm.fit(X_train_smote, y_train_smote)\n",
        "# 預測測試集的「機率」\n",
        "y_pred_proba_lgbm = final_lgbm.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# --- 尋找最佳機率門檻 ---\n",
        "print(\"尋找最佳機率門檻...\")\n",
        "best_f1_final = -1.0 # 初始化最佳 F1 分數\n",
        "best_supervised_threshold = 0.5 # 初始化最佳門檻\n",
        "# 在 0.01 到 0.99 之間，以 0.005 為間隔，精細搜索門檻\n",
        "for thresh in np.arange(0.01, 1.0, 0.005):\n",
        "    # 根據當前門檻，將機率轉換為 0 或 1 的二元預測\n",
        "    y_pred_binary = (y_pred_proba_lgbm >= thresh).astype(int)\n",
        "    # 計算當前門檻下的 F1 分數\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    # 如果當前的 F1 分數比已知的最好分數更高\n",
        "    if f1 > best_f1_final:\n",
        "        # 更新最佳 F1 分數\n",
        "        best_f1_final = f1\n",
        "        # 更新最佳門檻\n",
        "        best_supervised_threshold = thresh\n",
        "\n",
        "# --- 使用最佳門檻進行最終評估 ---\n",
        "print(f\"找到的最佳門檻為: {best_supervised_threshold:.3f}\")\n",
        "# 使用最佳門檻產生最終的預測結果\n",
        "y_pred_supervised_final = (y_pred_proba_lgbm >= best_supervised_threshold).astype(int)\n",
        "# 呼叫預先定義好的評估函式，印出詳細報告\n",
        "evaluation(y_test, y_pred_supervised_final, model_name=\"Supervised: LightGBM with Optuna\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJLUwo8boweJ"
      },
      "source": [
        "單元格 5：為非監督學習準備資料\n",
        "中文註解\n",
        "這是非監督式學習最關鍵的一步。我們將資料集分割為訓練集和測試集。但是，自動編碼器的訓練集 (X_train_unsup_normal) 只包含正常交易 (Class == 0)。這麼做的目的是讓模型深度學習正常交易的特徵。測試集 (X_test_unsup, y_test_unsup) 則保留其原始分佈，同時包含正常與詐欺交易，以便後續用來評估模型的異常偵測能力。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aBl9i68Goy6D",
        "outputId": "f197c89c-305f-444f-b63a-2f35e692e431"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 開始非監督式學習 (Autoencoder) ---\n"
          ]
        }
      ],
      "source": [
        "# --- 6. 為非監督學習準備資料 ---\n",
        "print(\"\\n--- 開始非監督式學習 (Autoencoder) ---\")\n",
        "sys.stdout.flush()\n",
        "\n",
        "# 將資料分割為訓練集和測試集\n",
        "data_unsup = data.copy()\n",
        "X_train_df, X_test_df = train_test_split(data_unsup, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
        "\n",
        "# 分離出正常的交易資料 (Class == 0) 用於訓練自動編碼器\n",
        "X_train_unsup_normal = X_train_df[X_train_df['Class'] == 0]\n",
        "X_train_unsup_normal = X_train_unsup_normal.drop(['Class'], axis=1).values\n",
        "\n",
        "# 準備測試集 (包含正常與詐欺案例)\n",
        "y_test_unsup = X_test_df['Class'].values\n",
        "X_test_unsup = X_test_df.drop(['Class'], axis=1).values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3Qx53qWo0V7"
      },
      "source": [
        "單元格 6：定義與編譯自動編碼器模型\n",
        "中文註解\n",
        "這裡我們定義了自動編碼器的結構。\n",
        "\n",
        "input_layer: 輸入層，維度等於特徵數量。\n",
        "encoder: 編碼器部分，透過兩個 Dense 層將高維輸入壓縮到一個較低的維度 (encoding_dim = 16)，形成一個「瓶頸層」。tanh 和 relu 是常用的激活函數。\n",
        "decoder: 解碼器部分，嘗試從瓶頸層的壓縮表示中，逐步重建回原始維度的資料。\n",
        "輸出層激活函數: 最後一層使用 'linear' 激活函數，因為我們的輸入特徵經過標準化後，是有正有負的，linear 允許輸出任何實數值，以便更好地重建。\n",
        "編譯: 我們使用 adam 優化器和 mean_squared_error (均方誤差) 作為損失函數，目標是最小化重建資料與原始資料之間的差異。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CTghMHgao8Kr"
      },
      "outputs": [],
      "source": [
        "# 定義自動編碼器架構\n",
        "input_dim = X_train_unsup_normal.shape[1]\n",
        "encoding_dim = 16 # 潛在空間維度\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "# 編碼器\n",
        "encoder = Dense(encoding_dim, activation=\"tanh\")(input_layer)\n",
        "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder) # 瓶頸層\n",
        "# 解碼器\n",
        "decoder = Dense(encoding_dim, activation='tanh')(encoder)\n",
        "decoder = Dense(input_dim, activation='linear')(decoder) # 輸出層\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_BV02Cyo-4Y"
      },
      "source": [
        "單元格 7：訓練自動編碼器\n",
        "中文註解\n",
        "此處執行模型的訓練。我們使用 autoencoder.fit() 函式，輸入和目標都是 X_train_unsup_normal。這正是自動編碼器的核心：模型的目标是學習如何讓輸出等於輸入。我們設定了訓練週期 (epochs=30) 和批次大小 (batch_size=64)，並將 verbose=0 以保持訓練過程的輸出簡潔。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52ebTMcBpAHs"
      },
      "outputs": [],
      "source": [
        "# --- 訓練自動編碼器 ---\n",
        "print(\"在正常的交易資料上訓練自動編碼器...\")\n",
        "sys.stdout.flush()\n",
        "autoencoder.fit(X_train_unsup_normal, X_train_unsup_normal,\n",
        "                epochs=30,\n",
        "                batch_size=64,\n",
        "                shuffle=True,\n",
        "                validation_split=0.2,\n",
        "                verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5obg6NXpCEp"
      },
      "source": [
        "單元格 8：計算重建誤差並尋找最佳門檻\n",
        "中文註解\n",
        "模型訓練完成後，我們用它來預測（重建）整個測試集 X_test_unsup。\n",
        "\n",
        "計算重建誤差：我們計算每筆測試資料的原始值與其重建值之間的「平均絕對誤差」(Mean Absolute Error, MAE)，這個誤差值反映了模型重建該筆資料的好壞程度。\n",
        "尋找最佳門檻：我們在一個可能的誤差範圍內 (np.linspace) 進行迭代搜索。對於每一個可能的門檻值，我們都計算其對應的精確率和召回率。\n",
        "目標導向搜索：如果某個門檻能讓模型的精確率超過 0.07827 且召回率超過 0.3650，我們就將其視為一個有效的解決方案。在所有有效的方案中，我們選擇那個能讓 F1-Score 最高的門檻作為最佳門檻。\n",
        "後備方案：如果沒有任何門檻能同時滿足上述兩個條件，則退而求其次，選擇能讓整體 F1-Score 最高的門檻。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EoWr9ucPpEOP",
        "outputId": "3c7dcc33-0f8a-4d13-8508-246ae0b928d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "在測試集上計算重建誤差...\n",
            "正在搜索最佳重建誤差門檻...\n",
            "✅ 找到最佳重建誤差門檻: 1.9136\n"
          ]
        }
      ],
      "source": [
        "# --- 7. 尋找最佳異常門檻 ---\n",
        "print(\"在測試集上計算重建誤差...\")\n",
        "# 使用訓練好的自動編碼器預測整個測試集\n",
        "X_pred_unsup = autoencoder.predict(X_test_unsup, verbose=0)\n",
        "\n",
        "# 計算原始測試資料與其重建版本之間的平均絕對誤差 (MAE)\n",
        "mae = np.mean(np.abs(X_pred_unsup - X_test_unsup), axis=1)\n",
        "\n",
        "print(\"正在搜索最佳重建誤差門檻...\")\n",
        "best_threshold_mae = 0\n",
        "best_f1_mae = -1.0\n",
        "solution_found_unsup = False\n",
        "\n",
        "# 迭代一系列可能的門檻值，尋找滿足目標的解\n",
        "thresholds_mae = np.linspace(np.min(mae), np.max(mae), 500)\n",
        "for threshold in thresholds_mae:\n",
        "    y_pred_mae = (mae > threshold).astype(int)\n",
        "    precision = precision_score(y_test_unsup, y_pred_mae, zero_division=0)\n",
        "    recall = recall_score(y_test_unsup, y_pred_mae, zero_division=0)\n",
        "\n",
        "    # 檢查當前門檻是否滿足指定的精確率與召回率目標\n",
        "    if precision > 0.07827 and recall > 0.3650:\n",
        "        solution_found_unsup = True\n",
        "        f1 = f1_score(y_test_unsup, y_pred_mae)\n",
        "        # 如果是有效解，檢查其 F1 分數是否為目前最佳\n",
        "        if f1 > best_f1_mae:\n",
        "            best_f1_mae = f1\n",
        "            best_threshold_mae = threshold\n",
        "\n",
        "if solution_found_unsup:\n",
        "    print(f\"✅ 找到最佳重建誤差門檻: {best_threshold_mae:.4f}\")\n",
        "else:\n",
        "    print(\"❌ 未能找到滿足特定目標的門檻。將選擇最大化 F1 分數的門檻。\")\n",
        "    # 如果沒有門檻滿足特定條件，則選擇使 F1 分數最高的門檻\n",
        "    f1_scores = [f1_score(y_test_unsup, (mae > t).astype(int)) for t in thresholds_mae]\n",
        "    best_threshold_mae = thresholds_mae[np.argmax(f1_scores)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWke4H7rpIXM"
      },
      "source": [
        "單元格 9：最終評估\n",
        "中文註解\n",
        "這是最後一步。我們使用上一部找到的 best_threshold_mae 作為最終的決策邊界。任何重建誤差大於此門檻的交易，都被分類為詐欺 (1)，否則為正常 (0)。最後，我們調用之前定義的 evaluation 函式，來印出模型在測試集上的最終、詳細的性能報告。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyHwCX7vtb3X"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ov7Ch-dpJR6"
      },
      "outputs": [],
      "source": [
        "# --- 8. 最終評估 ---\n",
        "# 根據選擇的最佳門檻對異常進行分類\n",
        "y_pred_unsup = (mae > best_threshold_mae).astype(int)\n",
        "\n",
        "# 評估最終性能\n",
        "evaluation(y_test_unsup, y_pred_unsup, model_name=\"自動編碼器 (非監督式)\")\n",
        "\n",
        "print(\"\\n分析完成。\")\n",
        "sys.stdout.flush()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14609694ad5f448e8aa0907dae7b4c8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37e77458a0384f5c831c4af958c0f8a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef9db00c678e4d80972e0fa2bd963916",
              "IPY_MODEL_9fc5500ea93941dcab8d1c2ce5d4aa49",
              "IPY_MODEL_fd9f7ba9c51148e083529c780eadba55"
            ],
            "layout": "IPY_MODEL_14609694ad5f448e8aa0907dae7b4c8c"
          }
        },
        "50feb335e1014fb896a583d38c563c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e3a1806541d45eeaf6f0bec0811f7cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8553066bc2c84da48a6d406c7d2edce9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fe9e7ccf29f416cb9ba15389f51a4e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9548bf11df6847f2a99d8ef894dbdea5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fc5500ea93941dcab8d1c2ce5d4aa49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9548bf11df6847f2a99d8ef894dbdea5",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f407bbdb7fd24438bb8ed8d17e9c7838",
            "value": 100
          }
        },
        "ef9db00c678e4d80972e0fa2bd963916": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fe9e7ccf29f416cb9ba15389f51a4e6",
            "placeholder": "​",
            "style": "IPY_MODEL_50feb335e1014fb896a583d38c563c2d",
            "value": "Best trial: 90. Best value: 0.847222: 100%"
          }
        },
        "f407bbdb7fd24438bb8ed8d17e9c7838": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd9f7ba9c51148e083529c780eadba55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8553066bc2c84da48a6d406c7d2edce9",
            "placeholder": "​",
            "style": "IPY_MODEL_7e3a1806541d45eeaf6f0bec0811f7cf",
            "value": " 100/100 [1:41:27&lt;00:00, 51.35s/it]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}