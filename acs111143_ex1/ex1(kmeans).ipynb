{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3658b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score, davies_bouldin_score,\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "import kagglehub\n",
    "\n",
    "# --- Settings ---\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = 0.3\n",
    "N_NORMAL_SEED = 1000\n",
    "N_FRAUD_SEED = 100\n",
    "N_PCA_COMPONENTS = 7\n",
    "ENSEMBLE_RUNS = 1\n",
    "\n",
    "# --- Load and prepare data ---\n",
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
    "# Drop Time, scale Amount\n",
    "data = data.drop(['Time'], axis=1)\n",
    "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "# Features and label\n",
    "X = data.drop(columns=['Class']).values\n",
    "y = data['Class'].astype(int).values\n",
    "# Train/test split stratified\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# --- Dimensionality Reduction with PCA ---\n",
    "pca = PCA(n_components=N_PCA_COMPONENTS, random_state=RANDOM_SEED)\n",
    "x_train_pca = pca.fit_transform(x_train)\n",
    "x_test_pca = pca.transform(x_test)\n",
    "\n",
    "# --- Seed samples for initialization ---\n",
    "normal_idx = np.where(y_train == 0)[0][:N_NORMAL_SEED]\n",
    "fraud_idx = np.where(y_train == 1)[0][:N_FRAUD_SEED]\n",
    "seed_X = np.vstack([x_train_pca[normal_idx], x_train_pca[fraud_idx]])\n",
    "seed_labels = np.hstack([np.zeros(len(normal_idx)), np.ones(len(fraud_idx))])\n",
    "# Compute centroids from seed samples\n",
    "seed_km = KMeans(n_clusters=2, init='k-means++', random_state=RANDOM_SEED)\n",
    "seed_km.fit(seed_X)\n",
    "centroids_init = seed_km.cluster_centers_\n",
    "\n",
    "# --- Ensemble of seeded KMeans ---\n",
    "predictions = np.zeros((ENSEMBLE_RUNS, len(x_test_pca)), dtype=int)\n",
    "for run in range(ENSEMBLE_RUNS):\n",
    "    km = KMeans(\n",
    "        n_clusters=2,\n",
    "        init=centroids_init,\n",
    "        n_init=1,\n",
    "        random_state=RANDOM_SEED + run\n",
    "    )\n",
    "    km.fit(x_train_pca)\n",
    "    predictions[run] = km.predict(x_test_pca)\n",
    "\n",
    "# --- Majority vote ---\n",
    "from scipy.stats import mode\n",
    "y_pred_majority = mode(predictions, axis=0).mode.ravel()\n",
    "\n",
    "# --- Align cluster labels to true classes ---\n",
    "cluster_ids = np.unique(y_pred_majority)\n",
    "cluster_map = {}\n",
    "for cid in cluster_ids:\n",
    "    mask = (y_pred_majority == cid)\n",
    "    # assign based on majority true label in test mask\n",
    "    cluster_map[cid] = np.bincount(y_test[mask]).argmax()\n",
    "\n",
    "y_pred_aligned = np.vectorize(cluster_map.get)(y_pred_majority)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2b47c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kmeans (Unsupervised) Evaluation:\n",
      "=============================================\n",
      "         Accuracy: 0.9989817773252344\n",
      "  Precision Score: 0.8144329896907216\n",
      "     Recall Score: 0.5337837837837838\n",
      "         F1 Score: 0.6448979591836734\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.81      0.53      0.64       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.91      0.77      0.82     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluation(y_true, y_pred, model_name=\"Model\"):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    print(f'\\n{model_name} Evaluation:')\n",
    "    print('===' * 15)\n",
    "    print(f'         Accuracy: {accuracy}')\n",
    "    print(f'  Precision Score: {precision}')\n",
    "    print(f'     Recall Score: {recall}')\n",
    "    print(f'         F1 Score: {f1}')\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# 執行評估\n",
    "evaluation(y_test, y_pred_aligned, model_name=\"Kmeans (Unsupervised)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
