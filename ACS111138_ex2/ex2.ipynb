{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48256517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, precision_recall_curve\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "import kagglehub\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# AutoEncoder 定義\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = 0.3\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        #壓縮成四維encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 4)\n",
    "        )\n",
    "        #解壓縮回原始維度decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(4, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
    "data['Class'] = data['Class'].astype(int)\n",
    "data = data.drop(['Time'], axis=1)\n",
    "data['Amount'] = RobustScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "X = data.drop(columns=['Class']).values\n",
    "y = data['Class'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d79e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA降維，去除冗餘特徵\n",
    "pca = PCA(n_components=20, random_state=RANDOM_SEED)\n",
    "x_train_pca = pca.fit_transform(x_train_scaled)\n",
    "x_test_pca = pca.transform(x_test_scaled)\n",
    "# IsolationForest(非監督)\n",
    "iso = IsolationForest(n_estimators=300, contamination=0.02, random_state=RANDOM_SEED)\n",
    "iso.fit(x_train_pca)\n",
    "anomaly_scores_if_train = iso.decision_function(x_train_pca)\n",
    "anomaly_scores_if_test = iso.decision_function(x_test_pca)\n",
    "iso_labels_train = iso.predict(x_train_pca) * 10\n",
    "iso_labels_test = iso.predict(x_test_pca) * 10\n",
    "# LOF(Local Outlier Factor)(非監督)\n",
    "lof = LocalOutlierFactor(n_neighbors=40, contamination=0.015, novelty=True)\n",
    "lof.fit(x_train_pca)\n",
    "lof_scores_train = lof.negative_outlier_factor_\n",
    "lof_scores_test = lof.decision_function(x_test_pca)\n",
    "lof_labels_train = lof.predict(x_train_pca) * 10\n",
    "lof_labels_test = lof.predict(x_test_pca) * 10\n",
    "# AutoEncoder訓練\n",
    "ae = AutoEncoder(input_dim=x_train_scaled.shape[1]).float()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(ae.parameters(), lr=0.01)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "x_tensor = torch.tensor(x_train_scaled, dtype=torch.float32)\n",
    "for _ in range(40):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = ae(x_tensor)\n",
    "    loss = criterion(outputs, x_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_recon = ae(torch.tensor(x_train_scaled, dtype=torch.float32)).numpy()\n",
    "    test_recon = ae(torch.tensor(x_test_scaled, dtype=torch.float32)).numpy()\n",
    "\n",
    "recon_error_train = np.mean((train_recon - x_train_scaled)**2, axis=1)\n",
    "recon_error_test = np.mean((test_recon - x_test_scaled)**2, axis=1)\n",
    "# 特徵整合\n",
    "x_train_all = np.hstack([\n",
    "    x_train_scaled, x_train_pca,\n",
    "    anomaly_scores_if_train.reshape(-1, 1),\n",
    "    iso_labels_train.reshape(-1, 1),\n",
    "    lof_scores_train.reshape(-1, 1), \n",
    "    lof_labels_train.reshape(-1, 1),\n",
    "    recon_error_train.reshape(-1, 1)\n",
    "])\n",
    "\n",
    "x_test_all = np.hstack([\n",
    "    x_test_scaled, x_test_pca,\n",
    "    anomaly_scores_if_test.reshape(-1, 1), \n",
    "    iso_labels_test.reshape(-1, 1),\n",
    "    lof_scores_test.reshape(-1, 1), \n",
    "    lof_labels_test.reshape(-1, 1),\n",
    "    recon_error_test.reshape(-1, 1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5a61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [15:02:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost 訓練\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300, max_depth=6, learning_rate=0.042,\n",
    "    gamma=0.12, subsample=0.95, colsample_bytree=0.87,\n",
    "    min_child_weight=1, reg_alpha=0.02, reg_lambda=1.0,\n",
    "    max_delta_step=3, tree_method='hist',\n",
    "    scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "    objective='binary:logistic', eval_metric='aucpr',\n",
    "    random_state=RANDOM_SEED, use_label_encoder=False\n",
    ")\n",
    "\n",
    "xgb_model.fit(x_train_all, y_train)\n",
    "y_proba = xgb_model.predict_proba(x_test_all)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "f1_scores = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_thresh = thresholds[best_idx]\n",
    "\n",
    "y_pred_final = (y_proba >= best_thresh).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db7ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hybrid Model Evaluation:\n",
      "========================================\n",
      "Accuracy       : 0.999508444225975\n",
      "Precision Score: 0.920634920634921\n",
      "Recall Score   : 0.783783783783784\n",
      "F1 Score       : 0.846715328467153\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.92      0.78      0.85       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.96      0.89      0.92     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluation(y_true, y_pred, model_name=\"Hybrid Model\"):\n",
    "    print(f\"\\n{model_name} Evaluation:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Accuracy       : {accuracy_score(y_true, y_pred):.15f}\")\n",
    "    print(f\"Precision Score: {precision_score(y_true, y_pred):.15f}\")\n",
    "    print(f\"Recall Score   : {recall_score(y_true, y_pred):.15f}\")\n",
    "    print(f\"F1 Score       : {f1_score(y_true, y_pred):.15f}\\n\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, digits=2))\n",
    "\n",
    "evaluation(y_test, y_pred_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
