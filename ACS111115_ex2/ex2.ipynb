{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#AutoEncoder+SMOTE+Xgboost\n"
      ],
      "metadata": {
        "id": "AjGR-Ku6l9hN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "233nWmotl8x6"
      },
      "outputs": [],
      "source": [
        "# 匯入系統相關套件並處理 MKL 錯誤（避免 Jupyter 或某些環境報錯）\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
        "\n",
        "# 匯入 PyTorch 相關模組\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# 匯入數值與資料處理模組\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 匯入 sklearn 中的訓練測試切分、標準化與評估工具\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, precision_recall_curve\n",
        ")\n",
        "\n",
        "# 匯入畫圖工具\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 匯入 XGBoost 分類器\n",
        "import xgboost as xgb\n",
        "\n",
        "# 匯入 KaggleHub 自動下載資料集\n",
        "import kagglehub\n",
        "\n",
        "# 匯入 SMOTE 資料增強工具\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# 下載並讀取 Kaggle 上的信用卡詐欺資料集\n",
        "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
        "\n",
        "# 移除 Time 欄位（時間戳記對模型幫助不大）\n",
        "data.drop('Time', axis=1, inplace=True)\n",
        "\n",
        "# 對 Amount 欄位進行標準化（均值為0、標準差為1）\n",
        "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
        "\n",
        "# 分離特徵 X 與標籤 Y\n",
        "X = data.drop(columns=['Class']).values\n",
        "Y = data['Class'].values\n",
        "\n",
        "# 依據標籤切出詐欺與正常樣本，以利觀察數量\n",
        "fraud = data[data['Class'] == 1]\n",
        "nonfraud = data[data['Class'] == 0]\n",
        "\n",
        "# 印出詐欺與非詐欺樣本數量\n",
        "print(f'Fraudulent:{len(fraud)}, non-fraudulent:{len(nonfraud)}')\n",
        "\n",
        "# 印出詐欺樣本比例\n",
        "print(f'The positive class (frauds) percentage: {len(fraud)/(len(fraud)+len(nonfraud))*100:.3f}%')\n",
        "\n",
        "# 切分訓練與測試集（保留原始類別比例）\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify=Y, random_state=42)\n",
        "\n",
        "# 從訓練集中取出所有非詐欺樣本，用來訓練 AutoEncoder\n",
        "X_train_auto = X_train[y_train == 0]\n",
        "\n",
        "# 轉換為 PyTorch tensor 格式\n",
        "X_train_auto_tensor = torch.tensor(X_train_auto, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "# 定義 AutoEncoder 結構（Encoder 擴張後壓縮，Decoder 還原）\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, encoding_dim):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 24),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24, encoding_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoding_dim, 24),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, input_dim)\n",
        "        )\n",
        "\n",
        "    # 定義 forward 過程：輸入經過 encoder 與 decoder\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "# 設定模型輸入維度與編碼維度\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 17\n",
        "\n",
        "# 初始化 AutoEncoder 模型\n",
        "model = AutoEncoder(input_dim, encoding_dim)\n",
        "\n",
        "# 使用 MSE 作為重建損失函數\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 使用 RMSprop 優化器\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
        "\n",
        "# 留出 10% 作為驗證集\n",
        "val_size = int(0.1 * X_train_auto.shape[0])\n",
        "train_tensor = torch.tensor(X_train_auto[:-val_size], dtype=torch.float32)\n",
        "val_tensor = torch.tensor(X_train_auto[-val_size:], dtype=torch.float32)\n",
        "\n",
        "# 訓練參數：訓練 100 輪，每批大小為 32\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "# 開始訓練 AutoEncoder\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    perm = torch.randperm(train_tensor.size(0))\n",
        "    epoch_train_loss = 0\n",
        "\n",
        "    # 每個 batch 執行訓練\n",
        "    for i in range(0, len(perm), BATCH_SIZE):\n",
        "        indices = perm[i:i + BATCH_SIZE]\n",
        "        batch = train_tensor[indices]\n",
        "        optimizer.zero_grad()\n",
        "        output = model(batch)\n",
        "        loss = criterion(output, batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss.item()\n",
        "\n",
        "    # 計算驗證損失\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_output = model(val_tensor)\n",
        "        val_loss = criterion(val_output, val_tensor).item()\n",
        "\n",
        "    train_losses.append(epoch_train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_losses[-1]:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "# 使用訓練好的 Encoder 將原始資料進行轉換\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    X_train_encoded = model.encoder(torch.tensor(X_train, dtype=torch.float32)).numpy()\n",
        "    X_test_encoded = model.encoder(torch.tensor(X_test, dtype=torch.float32)).numpy()\n",
        "\n",
        "# 對轉換後的資料使用 BorderlineSMOTE 平衡資料\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "smote = BorderlineSMOTE(kind='borderline-2', random_state=42)\n",
        "X_train_bal, y_train_bal = smote.fit_resample(X_train_encoded, y_train)\n",
        "\n",
        "# 印出平衡後的類別數量\n",
        "print(f\"\\nAfter SMOTE: Class 0 = {(y_train_bal == 0).sum()}, Class 1 = {(y_train_bal == 1).sum()}\")\n",
        "\n",
        "# 建立 XGBoost 分類器，使用 GPU 加速\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    colsample_bytree=1.0,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=7,\n",
        "    n_estimators=200,\n",
        "    subsample=0.8,\n",
        "    scale_pos_weight=2.5,\n",
        "    eval_metric='logloss',\n",
        "    tree_method='gpu_hist',\n",
        "    predictor='gpu_predictor',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 使用平衡後資料進行訓練\n",
        "xgb_model.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "# 對測試集預測機率（只取詐欺機率）\n",
        "y_pred_prob = xgb_model.predict_proba(X_test_encoded)[:, 1]\n",
        "\n",
        "# 計算 precision-recall 曲線與最佳 F1 分數的門檻\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
        "f1_scores = 2 * precision * recall / (precision + recall + 1e-8)\n",
        "best_idx = np.argmax(f1_scores)\n",
        "best_threshold = thresholds[best_idx]\n",
        "\n",
        "# 印出最佳門檻與對應的指標\n",
        "print(f\"\\nBest F1 Threshold: {best_threshold:.6f}\")\n",
        "print(f\"Precision: {precision[best_idx]:.4f}, Recall: {recall[best_idx]:.4f}, F1: {f1_scores[best_idx]:.4f}\")\n",
        "\n",
        "# 設定使用的預測門檻（可微調）\n",
        "adjusted_threshold = best_threshold\n",
        "y_pred = (y_pred_prob > adjusted_threshold).astype(int)\n",
        "\n",
        "# 定義模型評估函數\n",
        "def evaluation(y_true, y_pred, model_name=\"Model\"):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(f\"\\n{model_name} Evaluation:\")\n",
        "    print(\"===\" * 15)\n",
        "    print(\"         Accuracy:\", accuracy)\n",
        "    print(\"  Precision Score:\", precision)\n",
        "    print(\"     Recall Score:\", recall)\n",
        "    print(\"         F1 Score:\", f1)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "# 執行評估\n",
        "evaluation(y_test, y_pred, model_name=\"AutoEncoder + SMOTE + XGBoost\")\n",
        "\n",
        "# 畫出訓練與驗證損失圖\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"AutoEncoder Loss (Train & Val)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ]
}