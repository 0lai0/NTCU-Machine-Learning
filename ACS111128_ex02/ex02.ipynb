{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install xgboost optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWAturA2mIwo",
        "outputId": "1d4e1949-bc79-4eb7-dba8-0dad467a6443"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.1 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiDJx69EkpVc",
        "outputId": "8178c453-a908-4a0f-8d62-a3398ae0257b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraudulent:492, non-fraudulent:284315\n",
            "the positive class (frauds) percentage: 492/284807 (0.173%)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "import kagglehub\n",
        "\n",
        "# general setting. do not change TEST_SIZE\n",
        "RANDOM_SEED = 42\n",
        "TEST_SIZE = 0.3\n",
        "\n",
        "# load dataset（from kagglehub）\n",
        "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
        "data['Class'] = data['Class'].astype(int)\n",
        "\n",
        "# prepare data\n",
        "data = data.drop(['Time'], axis=1)\n",
        "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
        "\n",
        "fraud = data[data['Class'] == 1]\n",
        "nonfraud = data[data['Class'] == 0]\n",
        "print(f'Fraudulent:{len(fraud)}, non-fraudulent:{len(nonfraud)}')\n",
        "print(f'the positive class (frauds) percentage: {len(fraud)}/{len(fraud) + len(nonfraud)} ({len(fraud)/(len(fraud) + len(nonfraud))*100:.3f}%)')\n",
        "\n",
        "X = np.asarray(data.iloc[:, ~data.columns.isin(['Class'])])\n",
        "Y = np.asarray(data['Class'])\n",
        "\n",
        "# split training set and data set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#　計算詐騙與非詐騙的比例\n",
        "contamination = len(fraud) / len(nonfraud)\n",
        "scale_pos_weight = len(nonfraud) / len(fraud)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Step 1: 用 IsolationForest 做初步異常篩選，產生新特徵\n",
        "iso = IsolationForest(\n",
        "    # 異常比例\n",
        "    contamination=contamination,\n",
        "    # 使用 200 棵樹\n",
        "    n_estimators=200,\n",
        "    # 自動選擇樣本數\n",
        "    max_samples='auto',\n",
        "    random_state=RANDOM_SEED\n",
        "  )\n",
        "\n",
        "# 對訓練集做異常預測，回傳 +1 正常，-1 異常\n",
        "iso_train_pred = iso.fit_predict(X_train)\n",
        "# 對測試集也預測\n",
        "iso_test_pred = iso.predict(X_test)\n",
        "\n",
        "# 把 IsolationForest 預測結果轉成 0/1（1 代表異常）\n",
        "iso_train_feature = (iso_train_pred == -1).astype(int).reshape(-1, 1)\n",
        "iso_test_feature = (iso_test_pred == -1).astype(int).reshape(-1, 1)\n",
        "\n",
        "# 將新特徵與原特徵合併\n",
        "X_train_enhanced = np.hstack((X_train, iso_train_feature))\n",
        "X_test_enhanced = np.hstack((X_test, iso_test_feature))"
      ],
      "metadata": {
        "id": "N9dXKH42mob2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: 用 XGBoost 進行監督式分類\n",
        "xgb_model = XGBClassifier(\n",
        " # 樹的數量（弱分類器個數），越多可能提升效果，但計算成本也越高\n",
        "    n_estimators=211,\n",
        "    # 控制每棵樹對最終預測的貢獻，小學習率通常能提升泛化能力\n",
        "    learning_rate=0.168601190206765,\n",
        "    # 樹的最大深度控制模型複雜度與過擬合程度\n",
        "    max_depth=9,\n",
        "    # 每棵樹訓練時使用的樣本比例，用於防止過擬合\n",
        "    subsample=0.9989914764140614,\n",
        "    # 每棵樹訓練時使用的特徵比例，也能降低過擬合與特徵間干擾\n",
        "    colsample_bytree=0.7464806626828626,\n",
        "    # 分裂節點所需的最小資訊增益，數值越大越保守，有助於防止過擬合\n",
        "    gamma=0.4911060467180274,\n",
        "    # 類別不平衡處理：調整正負樣本的權重比例，提升對少數類別的辨識能力\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    # 葉節點最小樣本權重總和，限制葉節點最小樣本數，避免過度擬合小樣本\n",
        "    min_child_weight=1,\n",
        "    # 使用直方圖加速訓練，特別適合大數據\n",
        "    tree_method='hist',\n",
        "    # 模型訓練的評估指標，這裡選用 logloss 評估預測機率的準確性\n",
        "    eval_metric='logloss',\n",
        "    # 隨機種子，確保結果可重現\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train_enhanced, y_train.ravel())\n",
        "\n",
        "# 預測與評估\n",
        "y_pred = xgb_model.predict(X_test_enhanced)"
      ],
      "metadata": {
        "id": "KibOvuxbtyiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義評估函式，輸出常見指標\n",
        "def evaluation(y_true, y_pred, model_name=\"Model\"):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "    print(f'\\n{model_name} Evaluation:')\n",
        "    print('===' * 15)\n",
        "    print('         Accuracy:', accuracy)\n",
        "    print('  Precision Score:', precision)\n",
        "    print('     Recall Score:', recall)\n",
        "    print('         F1 Score:', f1)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "# 評估模型在測試集上的表現\n",
        "evaluation(y_test, y_pred, model_name=\"XGBClassifier\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_fDN0-Nsz86",
        "outputId": "55b14c4d-c94a-42fa-ecf1-ce2b74849af3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "XGBClassifier Evaluation:\n",
            "=============================================\n",
            "         Accuracy: 0.9996371850239341\n",
            "  Precision Score: 0.9133858267716536\n",
            "     Recall Score: 0.8529411764705882\n",
            "         F1 Score: 0.8821292775665399\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85307\n",
            "           1       0.91      0.85      0.88       136\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.96      0.93      0.94     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n"
          ]
        }
      ]
    }
  ]
}