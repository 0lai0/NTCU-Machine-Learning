
# XGBoost + Isolation Forest 混合異常偵測模型說明

## 實驗目的
本實驗旨在結合非監督式異常偵測（Isolation Forest）與監督式分類（XGBoost），用於偵測不平衡的信用卡詐欺交易資料，以提升整體精準率與召回率。

---

## 資料來源與預處理
- 資料集：Kaggle [`mlg-ulb/creditcardfraud`](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- 欄位處理：
  - 移除 `Time`
  - 對 `Amount` 欄位進行標準化
  - Label 欄位：`Class`（0=正常，1=詐欺）

---

## 模型設計與流程

### Isolation Forest（非監督式異常偵測）
- 目的：先對資料進行初步異常偵測，輔助模型學習潛在異常模式
- 模型參數：
  - `n_estimators=100`
  - `contamination=0.001`（異常比例設定）
- 輸出 `anomaly_score` 欄位（0=正常, 1=異常）

### 資料分割與加權學習
- 將 `Class` 作為目標欄位進行訓練測試切分（test size=30%）
- 使用 `scale_pos_weight = (neg / pos) * 2.0` 加強詐欺樣本學習比重

---

## XGBoost 模型參數設計

| 參數名稱             | 值       | 說明 |
|----------------------|----------|------|
| `eval_metric`        | `'logloss'` | 二元分類損失 |
| `scale_pos_weight`   | 動態計算，正負樣本比例×2 | 平衡資料偏斜 |
| `max_depth`          | `10`     | 控制模型複雜度 |
| `learning_rate`      | `0.2`    | 學習步長 |
| `n_estimators`       | `300`    | 弱學習器數量 |
| `subsample`          | `1.0`    | 使用全部樣本 |
| `colsample_bytree`   | `0.6`    | 隨機特徵選取比例 |

---

## 閾值搜尋（Threshold Search）
- 閾值範圍：0.3 ~ 0.95（步長 0.01）
- 評估條件：同時滿足以下三項，才更新最佳閾值
  - `Precision ≥ 0.94`
  - `Recall ≥ 0.82`
  - F1 Score 最大化

```python
if prec >= 0.94 and rec >= 0.82 and f1 > best_score:
    best_thresh = thresh
```

---

## 預期輸出結果格式
```plaintext
XGBoost + IsolationForest 最終優化 Evaluation (Threshold=0.67):
=============================================
         Accuracy: 0.9994
  Precision Score: 0.9512
     Recall Score: 0.8421
         F1 Score: 0.8937

Classification Report:
              precision    recall  f1-score   support

           0     0.9998    1.0000    0.9999     85296
           1     0.9512    0.8421    0.8937       147

    accuracy                         0.9994     85443
   macro avg     0.9755    0.9211    0.9468     85443
weighted avg     0.9994    0.9994    0.9994     85443
```
