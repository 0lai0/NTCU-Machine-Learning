# 信用卡詐欺預測分析（二）：非監督式學習與群聚方法

## 專案簡介

本專案為信用卡詐欺偵測系列的第二部分，聚焦於非監督式學習方法的應用。由於真實世界中常存在資料未經標註的情況，因此本次實驗採用異常偵測（Isolation Forest）與特徵降維（PCA）作為核心技術，並搭配監督式分類器 XGBoost，在半監督架構下強化詐欺交易辨識能力。

本實驗的重點在於如何有效利用少量甚至無標記資料，仍能達成合理的分類準確率與召回率。

## 資料處理

### 資料來源與結構

資料集來自 Kaggle 平台，含有 28 個經過主成分轉換的交易特徵（V1 ~ V28）、交易時間 `Time`、交易金額 `Amount`，以及是否為詐欺的類別標記 `Class`（0 為正常，1 為詐欺）。

### 前處理步驟

1. **欄位刪除**：`Time` 欄位因不具備解釋性或時序相關特徵，因此直接移除。
2. **數值標準化**：針對 `Amount` 欄位進行標準化處理，使資料平均值為 0、標準差為 1，避免金額尺度影響模型表現。
3. **資料切分**：透過 `train_test_split`，以 stratify 分層抽樣方式確保訓練集與測試集中詐欺樣本比例一致。

## 特徵降維與資料轉換

### PCA 主成分分析

使用 PCA 將原始特徵降維至數個主成分（可視為新的特徵），目的為：

- 降低資料維度以減少運算成本
- 移除冗餘資訊與雜訊
- 提高資料結構的可視化能力（可繪製 2D/3D 投影）

PCA 轉換後的資料仍保有大部分原始資料的變異性，可作為後續異常偵測與分類模型的輸入。

## 模型方法與架構設計

### Isolation Forest（IF）

- 一種基於隨機樹結構的非監督異常偵測方法，透過樣本在隨機切割中的孤立程度評估其異常性。
- `contamination` 參數設定為整體資料中詐欺比例（約 0.0017），告知模型預期異常比例。
- 輸出為異常分數與標籤：1 表正常，-1 表異常。

### 特徵融合與監督訓練

- 將 PCA 降維後的特徵與 Isolation Forest 異常分數進行組合，構成新特徵矩陣。
- 將此混合特徵作為輸入，利用 `XGBClassifier` 訓練最終分類器。
- 該方法實現了一種半監督學習策略：先透過非監督方法擷取資訊，再由監督模型進行分類。

## 評估方式與指標分析

### 評估指標

- **Accuracy**：模型預測正確的總比例，但不適合類別不平衡情境下做為唯一指標。
- **Precision**：在預測為詐欺的樣本中，有多少是真正的詐欺。
- **Recall**：在實際詐欺樣本中，有多少被正確偵測出來。
- **F1 Score**：Precision 與 Recall 的加權平均，平衡兩者表現。
- **Classification Report**：詳細列出每類別的 Precision、Recall、F1 分數與樣本數。

### 適用情境

- 若希望減少錯判正常為詐欺的風險（避免客戶困擾），可強化 Precision。
- 若希望提高偵測詐欺的成功率（減少漏判），則應提升 Recall。

## 總結

在沒有充足標籤資料的條件下，本專案結合了 PCA 與 Isolation Forest 的非監督方法來輔助建構監督式分類模型 XGBoost，有效提升了對詐欺樣本的辨識能力。

從實驗結果來看，此架構具有以下優勢：

- 能提升 Recall 表現，捕捉更多潛在詐欺樣本
- 異常分數作為新特徵，有助模型學習異常結構
- 對於標註資料不足的情境具有高度應用價值

未來可針對異常分數進行分段處理或進一步引入模型融合策略，提升整體預測穩定性。

## 參考來源

- Kaggle Dataset: https://www.kaggle.com/mlg-ulb/creditcardfraud
- Scikit-learn Isolation Forest: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html
- XGBoost 官方文件: https://xgboost.readthedocs.io/
- Scikit-learn PCA 文檔: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html
