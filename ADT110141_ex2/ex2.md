# 🛡️ 信用卡詐欺偵測：融合監督與非監督式學習

本專案旨在利用融合監督式與非監督式學習方法，提升對信用卡詐欺行為的偵測準確度，並解決資料極度不平衡的問題。

## 📁 使用資料集

- 來源：Kaggle
- 特徵數：30（PCA 降維後的匿名特徵 + 金額）
- 正常樣本：284,315 筆
- 詐欺樣本：492 筆（極度不平衡）

---

## 🔧 實作模型

### 1. 監督式學習：Random Forest

- 使用原始資料集中的 `Class` 標籤進行訓練
- 擅長處理非線性與不平衡資料

### 2. 非監督式學習：KMeans

- 不使用資料標籤
- 根據 Silhouette Score 自動尋找最佳群數
- 透過 Majority Voting 方式對齊預測標籤與實際標籤

### 3. 融合模型：Isolation Forest + XGBoost

- **Isolation Forest**：先對訓練資料偵測異常交易，輸出 anomaly score 作為新特徵欄位
- **XGBoost**：利用加上 anomaly score 的特徵資料進行監督式訓練與預測

---

## 📊 模型效能比較

| 模型名稱 | Accuracy | Precision | Recall | F1 Score |
|----------|----------|-----------|--------|----------|
| **Random Forest** | 0.9995 | 0.9576 | 0.7635 | 0.8496 |
| **KMeans (Unsupervised)** | 0.9983 | 0.0000 | 0.0000 | 0.0000 |
| **XGBoost + Isolation Forest 特徵** | 0.9995 | 0.9333 | 0.7568 | 0.8358 |

---

## 📌 模型輸出範例（融合模型）

```text
XGBoost with Isolation Forest Feature Evaluation:
=============================================
Accuracy:        0.9994850368081645
Precision Score: 0.9333333333333333
Recall Score:    0.7567567567567568
F1 Score:        0.835820895522388
```
---

## 🧠 小結論

- Isolation Forest 能有效地提前偵測出潛在異常行為，即使資料沒有標籤。

- 將非監督模型產出的異常分數加入 XGBoost 模型中，可顯著提高詐欺偵測的精度與召回率。

- 結果顯示：融合模型整體優於單一模型，能在維持高準確度的同時，提升對詐欺樣本的識別能力（Recall 與 F1 分數皆上升）。

