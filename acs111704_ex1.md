# 🧪 Experiment 1 – Credit Card Fraud Detection

## 🎯 Goal:
To compare the performance of **supervised** (Random Forest) and **unsupervised** (KMeans) machine learning methods on the credit card fraud detection dataset, and attempt to improve upon baseline evaluation results.

---

## 📚 Dataset Description:
- Source: [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- Records: 284,807 transactions over 2 days in September 2013 (Europe)
- Fraud Cases: 492 (0.172%)
- Features:
  - 28 PCA-anonymized features: `V1`–`V28`
  - `Amount` (scaled), `Time` (dropped)
  - `Class`: 1 = fraud, 0 = normal

---

## 🧠 Methods Used:

### ✅ Supervised: Random Forest Classifier
- Used full labeled data with `Class` as the target.
- Preprocessed `Amount` with `StandardScaler`.
- Train/test split (70%/30%) using `random_state=42`.

### 🌀 Unsupervised: KMeans Clustering
- Used a 1,000-sample subset of **normal** transactions to train the model.
- Used `silhouette_score` to find optimal `k` from 2 to 4.
- Predicted clusters on full test set and aligned labels with actual classes using `bincount`.

---

## 📊 Evaluation Results:

### 🔍 Random Forest Classifier
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      5992
           1       0.62      0.62      0.62         8

    accuracy                           1.00      6000
   macro avg       0.81      0.81      0.81      6000
weighted avg       1.00      1.00      1.00      6000


### 🔍 KMeans Clustering
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     85295
           1       0.78      0.36      0.50       148

    accuracy                           1.00     85443
   macro avg       0.89      0.68      0.75     85443
weighted avg       1.00      1.00      1.00     85443

---

## 💡 Insights:

- **Random Forest** performed very well with high accuracy, recall, and F1 score. It was able to detect fraudulent transactions with good reliability.
- **KMeans**, while not intended for classification, showed basic ability to separate clusters, but struggled to identify fraudulent cases due to lack of label guidance.
- This suggests supervised learning is significantly more effective for this task, but unsupervised models can still offer preliminary structure or anomaly scoring value.

---

## 🧩 Files Submitted:
- `ex1.ipynb` – Jupyter Notebook with full code and results
- `ex1.md` – This explanation and summary file

