# 實驗二報告:信用卡詐欺偵測報告

## 專案簡介

本專案旨在利用 Kaggle 的信用卡詐欺交易資料集，建立一個結合 Isolation Forest 與 XGBoost 的混合模型，進行二元分類以辨識詐欺交易行為。

資料集中僅有約 0.17% 的資料為詐欺樣本，屬於高度不平衡分類問題，因此採用異常偵測（Unsupervised）+ 監督式學習（Supervised）進行模型優化。

---

## 模型訓練與設計

### 前處理步驟：

* 使用 `StandardScaler` 標準化 `Amount` 欄位
* 移除時間欄位 `Time`
* 分割訓練與測試集（70% / 30%）

### 模型設計：

1. **Isolation Forest**

   * 目的：偵測異常樣本並作為額外特徵
   * 使用 `anomaly_score` 以及 `isolation_label` 作為 XGBoost 模型輸入
2. **XGBoost Classifier**

   * 用於訓練二元分類模型
   * 超參數調整如下：

     * `max_depth=7`
     * `n_estimators=710`
     * `learning_rate=0.031`
     * `subsample=0.91`
     * `colsample_bytree=0.84`
     * `scale_pos_weight=正常/詐欺樣本數比`

### 評估方法：

* 使用 `precision_recall_curve` 計算每個門檻下的 F1 分數
* 選擇 F1 分數最高的門檻作為最佳 threshold 進行分類

---

## Recall無法超過0.86

進行特徵強化與門檻調整，Recall 始終無法突破 0.86，其主要原因可能為：

1. **極端不平衡的資料**：詐欺交易僅佔不到 0.2%，模型為避免過度偵測產生高假陽性，因此傾向保守預測。

2. **XGBoost 預設偏保守**：即使調整 `scale_pos_weight`，XGBoost 仍可能傾向提高 precision 而非 recall。

3. **特徵強度不足**：目前僅加入 Isolation Forest 的異常分數，尚未進一步引入 LOF、PCA 或時間/頻率類特徵，導致模型分辨力有限。

4. **門檻區間離散**：在 precision ≈ 0.93 的門檻區間，常無法同時找到 recall > 0.86 且 F1 > 0.89 的門檻點，因此系統自動回退至 F1 最大值。

---

## 最終成果

```
Hybrid Model Evaluation:
==================================================
Accuracy       : 0.9996839998595555
Precision Score: 0.9658119658119658
Recall Score   : 0.8308823529411765
F1 Score       : 0.8932806324110671
```

該模型能在保持高準確率與高 precision 的情況下，達成不錯的 recall 與 F1 表現，為交易風險控管提供具實用性的詐欺偵測能力。

---

## 使用方法

1. 安裝 kagglehub 並下載資料：

```python
import kagglehub
path = kagglehub.dataset_download("mlg-ulb/creditcardfraud")
```

2. 載入並前處理資料：

```python
import pandas as pd
from sklearn.preprocessing import StandardScaler

df = pd.read_csv(f"{path}/creditcard.csv")
df['Amount'] = StandardScaler().fit_transform(df[['Amount']])
df = df.drop(columns=['Time'])
```

3. 執行完整程式碼，即可進行訓練與預測。

---


