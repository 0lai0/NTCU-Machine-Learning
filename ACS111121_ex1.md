# 信用卡詐欺預測分析：XGBoost 模型應用

# 信用卡詐欺預測分析：監督式學習（XGBoost 模型）

---

## 一、專案簡介

本專案致力於建立一套能有效預測信用卡詐欺行為的系統，透過監督式學習模型 XGBoost，針對具有標記的資料進行分類預測。資料集來自 Kaggle，包含匿名化特徵與實際交易金額與詐欺標記，資料嚴重不平衡（正類樣本極少）。

---

## 二、資料前處理步驟

1. **欄位處理**：移除 `Time` 欄位，避免時間偏見。
2. **標準化處理**：使用 `StandardScaler` 對 `Amount` 欄位進行標準化。
3. **資料切分**：以 7:3 比例使用 `train_test_split` 將資料切分為訓練與測試資料。

---

## 三、模型訓練與參數（XGBoost）


| 參數名稱           | 說明                                                   |
| ------------------ | ------------------------------------------------------ |
| `n_estimators`     | 決策樹數量，影響模型複雜度與訓練時間                   |
| `learning_rate`    | 每棵樹對預測的貢獻程度，小值增加穩定性但需較長訓練時間 |
| `max_depth`        | 決策樹的最大深度，避免過擬合                           |
| `scale_pos_weight` | 權重補償用於類別不平衡（負樣本 / 正樣本）              |
| `random_state`     | 控制隨機性，保證結果可重現                             |

---

## 四、模型評估指標

* **Accuracy**：總體預測正確率
* **Precision**：預測為詐欺的資料中有多少是真詐欺
* **Recall**：實際詐欺中有多少被正確找出（關鍵）
* **F1 Score**：Precision 與 Recall 的調和平均
* **Classification Report**：詳細分類表現
* **Precision-Recall Curve**：圖形化 threshold 調整依據

---

## 五、執行環境與套件

* `pandas`, `numpy`, `scikit-learn`, `xgboost`, `kagglehub`

---

## 六、使用方式

1. 使用 pip 安裝所需套件（建議於 Colab 執行）
2. 從 Kaggle 自動下載資料集（透過 `kagglehub`）
3. 執行資料預處理、模型訓練與評估步驟
4. 可根據應用需求調整 threshold 強化模型召回或精確能力

---

## 七、總結

XGBoost 是處理不平衡分類問題的強大工具，能在標記資料下提供穩定與高效的預測結果。特別在金融詐欺偵測中，其調整權重與精細預測能力對於業界具有實務價值。

---

## 八、參考資料

* XGBoost：[https://xgboost.readthedocs.io/](https://xgboost.readthedocs.io/)
* Scikit-learn：[https://scikit-learn.org/](https://scikit-learn.org/)
* Kaggle Dataset：[https://www.kaggle.com/mlg-ulb/creditcardfraud](https://www.kaggle.com/mlg-ulb/creditcardfraud)

## 專案簡介

本專案致力於建立一個能有效預測信用卡詐欺行為的模型，使用 Kaggle 所提供的資料集進行實作。該資料集真實模擬信用卡交易行為，但包含的詐欺樣本極少，造成正負類別高度不平衡，為模型設計帶來挑戰。

為解決此問題，本專案採用 XGBoost 演算法作為主要模型，並透過類別加權的方式強化對少數類別（詐欺）的識別能力。

## 技術流程說明

### 資料來源

- 資料集來自 Kaggle：「Credit Card Fraud Detection Dataset」
- 資料特徵為匿名化後的主成分（V1~V28）與原始交易金額（Amount）、時間（Time）及標記類別（Class）

### 資料前處理步驟

1. **欄位處理**：
   - 移除 `Time` 欄位，避免時間對模型造成偏見。
2. **數值標準化**：
   - 使用 `StandardScaler` 對 `Amount` 欄位標準化，避免數值尺度對模型影響。
3. **資料分割**：
   - 使用 `train_test_split` 將資料以 7:3 比例切分為訓練集與測試集，並設置隨機種子（random_state=42）確保可重現性。

## 模型訓練與設計

### 使用演算法

- **XGBoost（Extreme Gradient Boosting）**：
  - 是一種增強型樹模型，以梯度提升為基礎，在效能與準確度方面表現卓越。
  - 特別適合處理類別不平衡的分類問題。

### 不平衡資料處理

- 計算訓練集中正負樣本比例
- 使用 `scale_pos_weight` 參數調整正類樣本權重，使模型更關注詐欺樣本

### 模型訓練步驟

1. 初始化 `XGBClassifier`，設定關鍵參數（見下表）
2. 使用訓練資料進行模型擬合
3. 使用測試資料評估模型效能

## 主要模型參數


| 參數               | 說明                                                     |
| ------------------ | -------------------------------------------------------- |
| `n_estimators`     | 樹的總數，決定模型複雜度與訓練時間                       |
| `learning_rate`    | 每棵樹對最終預測的貢獻程度，小值增加模型穩定性但訓練較慢 |
| `max_depth`        | 單棵樹的最大深度，控制過擬合風險                         |
| `scale_pos_weight` | 正樣本權重比例，用來處理類別不平衡問題                   |
| `random_state`     | 控制隨機性，確保實驗可重現                               |
| `eval_metric`      | 設定評估指標，如`logloss` 或 `auc`                       |

## 模型評估指標

完成模型訓練後，評估指標將涵蓋：

- **Accuracy**：整體預測正確率
- **Precision**：被預測為詐欺中實際為詐欺的比例
- **Recall**：實際詐欺中被成功偵測的比例（關鍵）
- **F1 Score**：Precision 與 Recall 的加權平均
- **Classification Report**：顯示每類別的完整評估
- **Precision-Recall Curve**：幫助決定最佳 threshold 的圖形化工具

## 執行環境與依賴套件

本專案主要使用以下 Python 套件：

- `pandas`：資料處理
- `numpy`：數學運算
- `scikit-learn`：資料切分與指標評估
- `xgboost`：模型建構
- `kagglehub`：自動下載資料集

## 使用方式

1. 安裝所有必要套件（建議使用 pip 或在 Colab 執行）
2. 執行程式碼以載入資料、進行預處理與模型訓練
3. 觀察分類報告與 Precision-Recall 指標調整模型
4. 可透過閾值調整（例如 0.43）進行 Precision 與 Recall 間的權衡
5. 如有需要，可結合其他模型進行混合學習（例如與 Isolation Forest）

## 總結

本專案成功應用 XGBoost 模型於信用卡詐欺偵測任務，透過適當的資料預處理與類別不平衡處理策略，有效提升了對少數詐欺樣本的辨識能力。從模型訓練與評估結果來看，Precision 與 Recall 皆具有實務應用潛力，特別是在高正確率需求的金融領域。

未來可進一步根據實際應用場景，調整模型參數與預測門檻，達到最佳化詐欺偵測效果。

## 參考來源

- XGBoost 官方說明文件：https://xgboost.readthedocs.io/
- Scikit-learn 官方文件：https://scikit-learn.org/
- Kaggle Dataset: https://www.kaggle.com/mlg-ulb/creditcardfraud
