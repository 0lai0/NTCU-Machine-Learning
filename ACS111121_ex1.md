# 信用卡詐欺預測分析：監督與非監督模型

## 專案簡介

本專案旨在透過監督式學習（XGBoost）與非監督式學習（KMeans + PCA）方法，建構一套可有效預測與識別信用卡詐欺行為的系統。資料來源為 Kaggle 所提供的真實信用卡交易資料集，特點是極度不平衡的類別分布，其中正常交易遠多於詐欺交易。

為解決此問題，專案採用以下策略：

* 利用 XGBoost 進行精準分類並調整門檻優化 Precision 與 Recall
* 使用 PCA 進行降維與特徵壓縮，搭配 KMeans 做非監督分群探索

---

## 技術流程說明

### 資料來源

* Kaggle：「Credit Card Fraud Detection」資料集
* 特徵包含匿名化後的變數（V1\~V28）、原始交易金額（Amount）
* 標記欄位為 `Class`（0=正常，1=詐欺）

---

## 模型一：監督式學習（XGBoost）

### 資料預處理

1. 移除 `Time` 欄位，避免時間對模型預測造成偏差。
2. 使用 `StandardScaler` 對 `Amount` 欄位標準化，避免數值尺度影響模型學習。
3. 將資料依照 7:3 比例切分為訓練集與測試集，設置 `random_state=42` 確保實驗可重現。

### 類別不平衡處理

* 計算訓練集中正常與詐欺樣本數量比值，並作為 `scale_pos_weight` 參數
* 該參數可提升模型對少數類別（詐欺）的敏感度與偵測力

### 模型訓練與調參

使用 `XGBClassifier` 訓練模型，主要參數設定如下：


| 參數                    | 說明                                     |
| ----------------------- | ---------------------------------------- |
| `n_estimators=200`      | 使用 200 棵樹構成模型                    |
| `max_depth=6`           | 控制每棵樹的最大深度，避免過擬合         |
| `learning_rate=0.1`     | 控制每棵樹對最終預測的貢獻程度           |
| `subsample=0.8`         | 抽樣比例，避免過擬合                     |
| `colsample_bytree=0.8`  | 每棵樹隨機選取特徵比例，提升模型泛化能力 |
| `min_child_weight=5`    | 控制每棵樹葉節點的最小樣本權重           |
| `scale_pos_weight`      | 使用動態計算的類別比例，以處理不平衡問題 |
| `eval_metric='logloss'` | 使用對數損失函數作為評估基準             |

### 門檻選擇策略

使用 `precision_recall_curve` 計算不同門檻下的 Precision 與 Recall，找出同時滿足：

* Precision ≥ 94%
* Recall ≥ 82%
  的最佳 threshold 作為預測依據。

### 模型評估指標

* **Accuracy**：整體預測正確率
* **Precision**：預測為詐欺中實際為詐欺的比例
* **Recall**：實際詐欺中被成功偵測的比例（關鍵）
* **F1 Score**：Precision 與 Recall 的調和平均
* **Classification Report**：顯示每類別的完整評估

---

## 模型二：非監督式學習（KMeans + PCA）

### 特徵轉換與降維

1. 使用 `StandardScaler` 標準化數據（不含 `Class` 欄位）
2. 使用 PCA 壓縮特徵空間，保留 98% 累積變異量，降低雜訊干擾與運算成本

### 建立分群模型

* 使用 `KMeans(n_clusters=2)` 對正常與詐欺樣本混合資料進行分群
* 每次從原始資料中隨機抽樣：
  * 正常樣本：5000 筆
  * 詐欺樣本：500 筆
* 重複執行 5 次（ENSEMBLE\_RUNS = 5），對每次分群結果紀錄分類

### 預測整合策略

* 每次訓練後使用 `predict` 對測試集進行推論
* 統計所有執行結果的分群標籤，使用眾數（mode）作為最終預測標籤
* 再以原始標籤與最終預測進行比較

### 模型評估指標

* 與監督模型相同：Accuracy、Precision、Recall、F1 Score、Classification Report


---

## 執行環境與依賴套件

* `numpy`, `pandas`, `scikit-learn`, `xgboost`, `kagglehub`

---

## 使用方式

1. 安裝所需套件（建議於 Colab 中執行）

```bash
pip install pandas numpy scikit-learn xgboost kagglehub
```

2. 下載資料集（使用 `kagglehub.dataset_download("mlg-ulb/creditcardfraud")`）
3. 依照流程進行資料預處理、模型訓練與門檻選擇
4. 輸出分類報告與 Precision-Recall 指標圖表

---

## 總結

本專案成功優化監督式與非監督式學習模型，針對高度不平衡的信用卡詐欺資料進行分類與偵測。XGBoost 提供強大的分類準確率與精細門檻控制，而 KMeans + PCA 則可在無標籤場景中進行潛在詐欺樣本探索。

透過模型優化與多次實驗結果分析，本專案展現了在金融領域中有效應對詐欺偵測的應用潛力。

---

## 參考資料

* Kaggle Dataset：[https://www.kaggle.com/mlg-ulb/creditcardfraud](https://www.kaggle.com/mlg-ulb/creditcardfraud)
* XGBoost 官方文件：[https://xgboost.readthedocs.io/](https://xgboost.readthedocs.io/)
* Scikit-learn 官方文件：[https://scikit-learn.org/](https://scikit-learn.org/)
