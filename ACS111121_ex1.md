# 信用卡詐欺預測分析：監督與非監督模型應用

---

## 一、專案簡介

本專案致力於建立一套能有效預測信用卡詐欺行為的系統，結合監督式學習（Supervised Learning）與非監督式學習（Unsupervised Learning）模型來提升整體準確度與召回率。

資料集來自 Kaggle 平台，為一份實際模擬信用卡交易行為的數據，其中包含大量正常交易與極少數詐欺樣本，造成資料高度不平衡。

---

## 二、監督式學習模型：XGBoost 分類器

### 資料前處理步驟

1. **欄位處理**：移除 `Time` 欄位，避免時間偏見。
2. **標準化處理**：使用 `StandardScaler` 對 `Amount` 欄位進行標準化。
3. **資料切分**：以 7:3 比例使用 `train_test_split` 將資料切分為訓練與測試資料。

### 模型訓練與參數


| 參數名稱           | 說明                                                   |
| ------------------ | ------------------------------------------------------ |
| `n_estimators`     | 決策樹數量，影響模型複雜度與訓練時間                   |
| `learning_rate`    | 每棵樹對預測的貢獻程度，小值增加穩定性但需較長訓練時間 |
| `max_depth`        | 決策樹的最大深度，避免過擬合                           |
| `scale_pos_weight` | 權重補償用於類別不平衡（負樣本 / 正樣本）              |
| `random_state`     | 控制隨機性，保證結果可重現                             |

### 評估指標

* **Accuracy**：總體預測正確率
* **Precision**：預測為詐欺的資料中有多少是真詐欺
* **Recall**：實際詐欺中有多少被正確找出（關鍵）
* **F1 Score**：Precision 與 Recall 的調和平均
* **Classification Report**：詳細分類表現
* **Precision-Recall Curve**：圖形化 threshold 調整依據

---

## 三、非監督式學習模型：Isolation Forest

### 模型特性

Isolation Forest 為一種異常偵測演算法，無需標記資料即可運作，特別適用於詐欺樣本極度稀少的情境。

### 實作步驟

1. 移除 `Class` 標籤，純以 `V1`\~`V28` 與 `Amount` 作為輸入
2. 使用 `IsolationForest` 擬合全部資料
3. 預測每筆資料的 anomaly score，設定 threshold 決定是否為異常
4. 若資料集同時存在標記，可進行 Precision、Recall 等監督式指標的後驗評估

### 優點與限制

* ✅ 可應用於無標記資料，適合事前偵測或資料探勘
* ⚠ 較難對每一類別做出細緻分類（如無法明確標註為『詐欺』）

---

## 四、混合式策略建議（Hybrid Model）

本專案可延伸採用混合學習策略：

* 將 Isolation Forest 的異常分數作為新特徵，輸入至 XGBoost 進行二階段分類
* 或將兩者結果做 soft voting 或 weighted average 決策融合

此策略可兼顧無監督探索與有監督學習的優勢，提升模型在不同場景下的泛化能力。

---

## 五、執行環境與套件

* `pandas`, `numpy`, `scikit-learn`, `xgboost`, `kagglehub`

---

## 六、使用方式

1. 使用 pip 安裝所需套件（建議於 Colab 執行）
2. 從 Kaggle 自動下載資料集（透過 `kagglehub`）
3. 執行資料預處理、模型訓練與評估步驟
4. 可根據應用需求調整 threshold 或採用混合模型強化效果

---

## 七、總結

本專案展示了監督與非監督學習在詐欺偵測任務中的互補角色。XGBoost 擅長處理標記資料並提供高精度預測，Isolation Forest 則能無需標記偵測潛在異常樣本。

透過整合兩種方法，我們得以建構更具彈性與實用性的詐欺偵測模型，為金融防詐場景提供強化方案。

---

## 八、參考資料

* XGBoost：[https://xgboost.readthedocs.io/](https://xgboost.readthedocs.io/)
* Scikit-learn：[https://scikit-learn.org/](https://scikit-learn.org/)
* Kaggle Dataset：[https://www.kaggle.com/mlg-ulb/creditcardfraud](https://www.kaggle.com/mlg-ulb/creditcardfraud)
