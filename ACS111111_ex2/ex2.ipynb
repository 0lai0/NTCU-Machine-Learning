{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8026d4bc",
   "metadata": {},
   "source": [
    "# 資料處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a4af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import kagglehub\n",
    "\n",
    "# general setting. do not change TEST_SIZE\n",
    "# 這個不能動\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = 0.3\n",
    "\n",
    "################################ 資料處理 ####################################\n",
    "\n",
    "# load dataset（from kagglehub）\n",
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
    "# 0 for nonfraud 1 for fraud\n",
    "data[\"Class\"] = data[\"Class\"].astype(int)\n",
    "\n",
    "# prepare data\n",
    "data = data.drop([\"Time\"], axis=1)  # 去除 time\n",
    "data[\"Amount\"] = StandardScaler().fit_transform(\n",
    "    data[\"Amount\"].values.reshape(-1, 1)\n",
    ")  # 標準化\n",
    "\n",
    "# 計算詐騙和正常交易的數量 (資料集極度不平衡)\n",
    "fraud = data[data[\"Class\"] == 1]\n",
    "nonfraud = data[data[\"Class\"] == 0]\n",
    "print(f\"Fraudulent:{len(fraud)}, non-fraudulent:{len(nonfraud)}\")\n",
    "print(\n",
    "    f\"the positive class (frauds) percentage: {len(fraud)}/{len(fraud) + len(nonfraud)} ({len(fraud)/(len(fraud) + len(nonfraud))*100:.3f}%)\"\n",
    ")\n",
    "\n",
    "# 選擇非class的值轉成numpy array 且如果原本就是np array時不複製\n",
    "X = np.asarray(data.iloc[:, ~data.columns.isin([\"Class\"])])\n",
    "# 最佳化為 Pandas → NumPy 的不複製轉換\n",
    "Y = data[\"Class\"].to_numpy()\n",
    "\n",
    "# split training set and data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=TEST_SIZE, random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb02d98",
   "metadata": {},
   "source": [
    "# 非監督"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806422f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.6489 - val_loss: 0.3627\n",
      "Epoch 2/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.3389 - val_loss: 0.3006\n",
      "Epoch 3/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2953 - val_loss: 0.2806\n",
      "Epoch 4/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2762 - val_loss: 0.2723\n",
      "Epoch 5/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2638 - val_loss: 0.2577\n",
      "Epoch 6/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2530 - val_loss: 0.2475\n",
      "Epoch 7/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2425 - val_loss: 0.2371\n",
      "Epoch 8/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2340 - val_loss: 0.2315\n",
      "Epoch 9/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2272 - val_loss: 0.2221\n",
      "Epoch 10/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2190 - val_loss: 0.2206\n",
      "Epoch 11/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2144 - val_loss: 0.2162\n",
      "Epoch 12/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2110 - val_loss: 0.2124\n",
      "Epoch 13/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2078 - val_loss: 0.2110\n",
      "Epoch 14/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.2051 - val_loss: 0.2091\n",
      "Epoch 15/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.2012 - val_loss: 0.2046\n",
      "Epoch 16/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.2005 - val_loss: 0.1986\n",
      "Epoch 17/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1956 - val_loss: 0.1961\n",
      "Epoch 18/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.1919 - val_loss: 0.2000\n",
      "Epoch 19/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1895 - val_loss: 0.1941\n",
      "Epoch 20/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1869 - val_loss: 0.1877\n",
      "Epoch 21/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1831 - val_loss: 0.1832\n",
      "Epoch 22/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.1810 - val_loss: 0.1817\n",
      "Epoch 23/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1788 - val_loss: 0.1782\n",
      "Epoch 24/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1765 - val_loss: 0.1816\n",
      "Epoch 25/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.1760 - val_loss: 0.1837\n",
      "Epoch 26/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1735 - val_loss: 0.1764\n",
      "Epoch 27/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1712 - val_loss: 0.1882\n",
      "Epoch 28/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1732 - val_loss: 0.1764\n",
      "Epoch 29/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1696 - val_loss: 0.1941\n",
      "Epoch 30/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.1722 - val_loss: 0.1767\n",
      "Epoch 31/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.1670 - val_loss: 0.1683\n",
      "Epoch 32/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.1668 - val_loss: 0.1724\n",
      "Epoch 33/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1656 - val_loss: 0.1686\n",
      "Epoch 34/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1654 - val_loss: 0.1675\n",
      "Epoch 35/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1630 - val_loss: 0.1683\n",
      "Epoch 36/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.1634 - val_loss: 0.1704\n",
      "Epoch 37/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.1634 - val_loss: 0.1627\n",
      "Epoch 38/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.1607 - val_loss: 0.1682\n",
      "Epoch 39/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1642 - val_loss: 0.1636\n",
      "Epoch 40/40\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.1604 - val_loss: 0.1654\n",
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 815us/step\n",
      "\n",
      "AutoEncoder Evaluation:\n",
      "=============================================\n",
      "         Accuracy: 0.9985136289690203\n",
      "  Precision Score: 0.5263157894736842\n",
      "     Recall Score: 0.6617647058823529\n",
      "         F1 Score: 0.5863192182410424\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.53      0.66      0.59       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.76      0.83      0.79     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "AutoEncoder Evaluation:\n",
      "=============================================\n",
      "         Accuracy: 0.9986423697669792\n",
      "  Precision Score: 0.5666666666666667\n",
      "     Recall Score: 0.625\n",
      "         F1 Score: 0.5944055944055944\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.57      0.62      0.59       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.78      0.81      0.80     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "AutoEncoder Evaluation:\n",
      "=============================================\n",
      "         Accuracy: 0.9987477031471274\n",
      "  Precision Score: 0.6124031007751938\n",
      "     Recall Score: 0.5808823529411765\n",
      "         F1 Score: 0.5962264150943396\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.61      0.58      0.60       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.81      0.79      0.80     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "AutoEncoder Evaluation:\n",
      "=============================================\n",
      "         Accuracy: 0.9987008883115059\n",
      "  Precision Score: 0.616822429906542\n",
      "     Recall Score: 0.4852941176470588\n",
      "         F1 Score: 0.5432098765432098\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.62      0.49      0.54       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.81      0.74      0.77     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "AutoEncoder Evaluation:\n",
      "=============================================\n",
      "         Accuracy: 0.9988062216916541\n",
      "  Precision Score: 0.6976744186046512\n",
      "     Recall Score: 0.4411764705882353\n",
      "         F1 Score: 0.5405405405405406\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.70      0.44      0.54       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.85      0.72      0.77     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\u001b[1m6231/6231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 765us/step\n",
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 764us/step\n",
      "\u001b[1m6231/6231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 713us/step\n",
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 736us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# 只拿正常樣本訓練\n",
    "X_train_auto = X_train[y_train == 0]\n",
    "\n",
    "# 建立 AutoEncoder 結構\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 18  # 壓縮\n",
    "hidden_dim = int(encoding_dim / 2)\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "# Encoder\n",
    "encoder = Dense(29, activation=\"tanh\", activity_regularizer=regularizers.l1(1e-5))(\n",
    "    input_layer\n",
    ")\n",
    "encoder = Dense(17, activation=\"tanh\")(encoder)\n",
    "# 取出最重要的8個特徵\n",
    "latent_output = Dense(8, activation=\"relu\")(encoder)\n",
    "\n",
    "# Decoder\n",
    "decoder = Dense(17, activation=\"relu\")(latent_output)\n",
    "decoder = Dense(29, activation=\"tanh\")(decoder)\n",
    "decoder = Dense(input_dim, activation=\"linear\")(decoder)  # 回到原始維度\n",
    "\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "# 建出 Encoder 模型\n",
    "encoder_model = Model(inputs=input_layer, outputs=latent_output)\n",
    "\n",
    "def evaluation(y_true, y_pred, model_name=\"Model\"):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n{model_name} Evaluation:\")\n",
    "    print(\"===\" * 15)\n",
    "    print(\"         Accuracy:\", accuracy)\n",
    "    print(\"  Precision Score:\", precision)\n",
    "    print(\"     Recall Score:\", recall)\n",
    "    print(\"         F1 Score:\", f1)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "# 訓練\n",
    "autoencoder.fit(\n",
    "    X_train_auto,\n",
    "    X_train_auto,\n",
    "    epochs=40,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "X_test_pred = autoencoder.predict(X_test)\n",
    "mse = np.mean(np.power(X_test - X_test_pred, 2), axis=1)\n",
    "\n",
    "for c in [99.8, 99.825, 99.85, 99.875, 99.9]:\n",
    "    threshold = np.percentile(mse, c)\n",
    "    y_pred = (mse > threshold).astype(int)\n",
    "\n",
    "    evaluation(y_test, y_pred, model_name=\"AutoEncoder\")\n",
    "\n",
    "\n",
    "# 計算 reconstruction error (可加到特徵中)\n",
    "X_train_pred = autoencoder.predict(X_train)\n",
    "X_test_pred = autoencoder.predict(X_test)\n",
    "\n",
    "# 和原資料合併\n",
    "X_train_latent = encoder_model.predict(X_train)\n",
    "X_test_latent = encoder_model.predict(X_test)\n",
    "\n",
    "\n",
    "train_mse = np.mean(np.power(X_train - X_train_pred, 2), axis=1).reshape(-1, 1)\n",
    "test_mse = np.mean(np.power(X_test - X_test_pred, 2), axis=1).reshape(-1, 1)\n",
    "\n",
    "# 加上 AE 重建誤差作為額外特徵\n",
    "X_train_aug = np.hstack([X_train, train_mse])\n",
    "X_test_aug = np.hstack([X_test, test_mse])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb9dc1c",
   "metadata": {},
   "source": [
    "# 監督"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eafc17cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGB-threshold 0.900  Evaluation:\n",
      "=============================================\n",
      "         Accuracy: 0.9996839998595555\n",
      "  Precision Score: 0.9658119658119658\n",
      "     Recall Score: 0.8308823529411765\n",
      "         F1 Score: 0.8932806324110671\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.97      0.83      0.89       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.98      0.92      0.95     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Train F1: 1.0\n",
      "Test  F1: 0.8679245283018868\n",
      "\n",
      "XGB-threshold 0.950  Evaluation:\n",
      "=============================================\n",
      "         Accuracy: 0.9996722961506501\n",
      "  Precision Score: 0.9655172413793104\n",
      "     Recall Score: 0.8235294117647058\n",
      "         F1 Score: 0.8888888888888888\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.97      0.82      0.89       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.98      0.91      0.94     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Train F1: 1.0\n",
      "Test  F1: 0.8679245283018868\n",
      "\n",
      "XGB-threshold 0.960  Evaluation:\n",
      "=============================================\n",
      "         Accuracy: 0.9996722961506501\n",
      "  Precision Score: 0.9655172413793104\n",
      "     Recall Score: 0.8235294117647058\n",
      "         F1 Score: 0.8888888888888888\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.97      0.82      0.89       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.98      0.91      0.94     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Train F1: 1.0\n",
      "Test  F1: 0.8679245283018868\n",
      "\n",
      "XGB-threshold 0.970  Evaluation:\n",
      "=============================================\n",
      "         Accuracy: 0.9996839998595555\n",
      "  Precision Score: 0.9739130434782609\n",
      "     Recall Score: 0.8235294117647058\n",
      "         F1 Score: 0.8924302788844621\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.97      0.82      0.89       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.99      0.91      0.95     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Train F1: 1.0\n",
      "Test  F1: 0.8679245283018868\n",
      "\n",
      "XGB-threshold 0.975  Evaluation:\n",
      "=============================================\n",
      "         Accuracy: 0.9996839998595555\n",
      "  Precision Score: 0.9739130434782609\n",
      "     Recall Score: 0.8235294117647058\n",
      "         F1 Score: 0.8924302788844621\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.97      0.82      0.89       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.99      0.91      0.95     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Train F1: 1.0\n",
      "Test  F1: 0.8679245283018868\n",
      "\n",
      "XGB-threshold 0.980  Evaluation:\n",
      "=============================================\n",
      "         Accuracy: 0.9996957035684608\n",
      "  Precision Score: 0.9824561403508771\n",
      "     Recall Score: 0.8235294117647058\n",
      "         F1 Score: 0.896\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.98      0.82      0.90       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.99      0.91      0.95     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Train F1: 1.0\n",
      "Test  F1: 0.8679245283018868\n",
      "\n",
      "XGB-threshold 0.990  Evaluation:\n",
      "=============================================\n",
      "         Accuracy: 0.9996839998595555\n",
      "  Precision Score: 0.990990990990991\n",
      "     Recall Score: 0.8088235294117647\n",
      "         F1 Score: 0.8906882591093117\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.99      0.81      0.89       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       1.00      0.90      0.95     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Train F1: 1.0\n",
      "Test  F1: 0.8679245283018868\n",
      "\n",
      "XGB-threshold 0.995  Evaluation:\n",
      "=============================================\n",
      "         Accuracy: 0.9996605924417448\n",
      "  Precision Score: 0.9908256880733946\n",
      "     Recall Score: 0.7941176470588235\n",
      "         F1 Score: 0.8816326530612245\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.99      0.79      0.88       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       1.00      0.90      0.94     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Train F1: 1.0\n",
      "Test  F1: 0.8679245283018868\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "########################## train model ################################\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=8,\n",
    "    # 處理資料集不平衡\n",
    "    scale_pos_weight=len(nonfraud) / len(fraud),\n",
    "    eval_metric=\"logloss\",\n",
    "    learning_rate=0.1,\n",
    "    random_state=RANDOM_SEED,  # 42\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train_aug,\n",
    "    y_train,\n",
    ")\n",
    "\n",
    "y_proba = xgb_model.predict_proba(X_test_aug)[:, 1]\n",
    "\n",
    "\n",
    "def evaluation(y_true, y_pred, model_name=\"Model\"):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n{model_name} Evaluation:\")\n",
    "    print(\"===\" * 15)\n",
    "    print(\"         Accuracy:\", accuracy)\n",
    "    print(\"  Precision Score:\", precision)\n",
    "    print(\"     Recall Score:\", recall)\n",
    "    print(\"         F1 Score:\", f1)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "# 嘗試不同 threshold\n",
    "for threshold in [0.9, 0.95, 0.96, 0.97, 0.975, 0.98, 0.99, 0.995]:\n",
    "    y_pred_thresh = (y_proba > threshold).astype(int)\n",
    "    evaluation(y_test, y_pred_thresh, model_name=f\"XGB-threshold {threshold:.3f} \")\n",
    "\n",
    "    y_train_pred = xgb_model.predict(X_train_aug)\n",
    "    y_test_pred = xgb_model.predict(X_test_aug)\n",
    "\n",
    "    f1_train = f1_score(y_train, y_train_pred)\n",
    "    f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    print(\"Train F1:\", f1_train)\n",
    "    print(\"Test  F1:\", f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c39a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": [50, 75, 100, 125, 150],\n",
    "    \"max_depth\": [6, 7, 8, 9],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"scale_pos_weight\": [len(nonfraud) / len(fraud), len(nonfraud) * 2 / len(fraud)],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    XGBClassifier(random_state=42), param_grid=params, scoring=\"f1\", cv=3, n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_aug, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
