{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "import kagglehub\n",
        "from xgboost import XGBClassifier, callback\n",
        "\n",
        "# general setting. do not change TEST_SIZE\n",
        "RANDOM_SEED = 42\n",
        "TEST_SIZE = 0.3"
      ],
      "metadata": {
        "id": "PBpx9he8GTtv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset（from kagglehub）\n",
        "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
        "data['Class'] = data['Class'].astype(int)"
      ],
      "metadata": {
        "id": "n7ZfvEeIF8AS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare data\n",
        "data = data.drop(['Time'], axis=1)\n",
        "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
        "\n",
        "fraud = data[data['Class'] == 1]\n",
        "nonfraud = data[data['Class'] == 0]\n",
        "print(f'Fraudulent:{len(fraud)}, non-fraudulent:{len(nonfraud)}')\n",
        "print(f'the positive class (frauds) percentage: {len(fraud)}/{len(fraud) + len(nonfraud)} ({len(fraud)/(len(fraud) + len(nonfraud))*100:.3f}%)')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glc_nLvIGknZ",
        "outputId": "1105eab9-45ce-4d53-ac04-b51b1e79414a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraudulent:492, non-fraudulent:284315\n",
            "the positive class (frauds) percentage: 492/284807 (0.173%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Time 拿掉\n",
        "- Amount 限制範圍在 -1 ~ 1\n",
        "- Class 前面被轉為 int，只有 1 / 0\n"
      ],
      "metadata": {
        "id": "sL3evV-UN_1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define evaluation function\n",
        "def evaluation(y_true, y_pred, model_name=\"Model\"):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "    print(f'\\n{model_name} Evaluation:')\n",
        "    print('===' * 15)\n",
        "    print('         Accuracy:', accuracy)\n",
        "    print('  Precision Score:', precision)\n",
        "    print('     Recall Score:', recall)\n",
        "    print('         F1 Score:', f1)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "id": "ZzG4-eyj63zA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RandomForest"
      ],
      "metadata": {
        "id": "F3x5VZDvHnLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "測試結果：\n",
        "- depth 8~10 差異不大，但似乎 8 是最佳\n",
        "- 數的數量大概 500 就好，因為在 8 差不多是極限\n",
        "- subsample 比例 0.7 目前最好，繼續向上或往下都會掉下去\n",
        "- colsample_bytree 用 1 會是最好\n",
        "- learning_rate 其實就直接抓最小，目前還沒遇到過擬合"
      ],
      "metadata": {
        "id": "IheocmazCdSE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 測試最佳參數"
      ],
      "metadata": {
        "id": "KuBoReR3D_u2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.asarray(data.iloc[:,~data.columns.isin(['Class'])])\n",
        "Y = np.asarray(data.iloc[:, data.columns == 'Class'])\n",
        "\n",
        "# split training set and data set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
        "\n",
        "\n",
        "# 準備收集結果的 list\n",
        "param_grid = [\n",
        "    # {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8},\n",
        "    # {'n_estimators': 220, 'max_depth': 6, 'learning_rate': 0.12, 'subsample': 0.8, 'colsample_bytree': 1.0},\n",
        "    # {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.10, 'subsample': 0.8, 'colsample_bytree': 0.8},\n",
        "    # {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.10, 'subsample': 0.8, 'colsample_bytree': 0.8},\n",
        "    # {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8},\n",
        "    # {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.02, 'subsample': 0.8, 'colsample_bytree': 0.8},\n",
        "    # {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8},\n",
        "    # {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.02, 'subsample': 0.8, 'colsample_bytree': 1.0},\n",
        "    # {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.02, 'subsample': 1.0, 'colsample_bytree': 1.0},\n",
        "    # {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.02, 'subsample': 0.8, 'colsample_bytree': 1.0},\n",
        "    {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.02, 'subsample': 0.7, 'colsample_bytree': 1.0},\n",
        "    {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.02, 'subsample': 0.75, 'colsample_bytree': 1.0},\n",
        "    {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.02, 'subsample': 0.65, 'colsample_bytree': 1.0},\n",
        "    {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.02, 'subsample': 0.725, 'colsample_bytree': 1.0},\n",
        "]\n",
        "\n",
        "results = []\n",
        "for params in param_grid:\n",
        "    # 建立 GPU 版 XGBoost\n",
        "    model = XGBClassifier(\n",
        "        tree_method='hist',\n",
        "        device='cuda',\n",
        "        scale_pos_weight=2,\n",
        "        gamma=0.05,\n",
        "        eval_metric='logloss',\n",
        "        random_state=42,\n",
        "        **params\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    # 預測\n",
        "    y_pred = model.predict(X_test)\n",
        "    # 計算指標\n",
        "    results.append({\n",
        "        **params,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'F1': f1_score(y_test, y_pred)\n",
        "    })\n",
        "    # evaluation(y_test, y_pred, model_name=\"XGB:\")\n",
        "\n",
        "# 將結果放入 DataFrame\n",
        "df_results = pd.DataFrame(results)\n",
        "print(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C4lqJqmGt3Y",
        "outputId": "d60ba3eb-c625-47e3-f707-68485347d460"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   n_estimators  max_depth  learning_rate  subsample  colsample_bytree  \\\n",
            "0           500          8           0.02      0.700               1.0   \n",
            "1           500          8           0.02      0.750               1.0   \n",
            "2           500          8           0.02      0.650               1.0   \n",
            "3           500          8           0.02      0.725               1.0   \n",
            "\n",
            "   Accuracy  Precision    Recall        F1  \n",
            "0  0.999707   0.966387  0.845588  0.901961  \n",
            "1  0.999661   0.934959  0.845588  0.888031  \n",
            "2  0.999696   0.958333  0.845588  0.898438  \n",
            "3  0.999684   0.950413  0.845588  0.894942  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best = XGBClassifier(\n",
        "    tree_method='hist',\n",
        "    device='cuda',\n",
        "    n_estimators=500,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.02,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=1.0,\n",
        "    scale_pos_weight=2,\n",
        "    gamma=0.05,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "xgb_best.fit(X_train, y_train)\n",
        "y_pred_best = xgb_best.predict(X_test)\n",
        "\n",
        "evaluation(y_test, y_pred_best, model_name=\"XGB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j3h7ny_GwIK",
        "outputId": "f0d45af6-2261-4723-ab0b-5912db4ee6a0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:43:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "XGB Evaluation:\n",
            "=============================================\n",
            "         Accuracy: 0.9997074072773662\n",
            "  Precision Score: 0.9663865546218487\n",
            "     Recall Score: 0.8455882352941176\n",
            "         F1 Score: 0.9019607843137255\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85307\n",
            "           1       0.97      0.85      0.90       136\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.98      0.92      0.95     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "原始數據：\n",
        "```\n",
        "Random Forest Evaluation:\n",
        "=============================================\n",
        "         Accuracy: 0.9996137776061234\n",
        "  Precision Score: 0.9478260869565217\n",
        "     Recall Score: 0.8014705882352942\n",
        "         F1 Score: 0.8685258964143426\n",
        "\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00     85307\n",
        "           1       0.95      0.80      0.87       136\n",
        "\n",
        "    accuracy                           1.00     85443\n",
        "   macro avg       0.97      0.90      0.93     85443\n",
        "weighted avg       1.00      1.00      1.00     85443\n",
        "```"
      ],
      "metadata": {
        "id": "2nMbr0ExRrEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KMeans"
      ],
      "metadata": {
        "id": "yuJZl3jZHgIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, silhouette_score\n",
        ")\n",
        "from scipy.stats import mode\n",
        "import kagglehub\n",
        "\n",
        "# --- Load and preprocess data ---\n",
        "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
        "data = data.drop(columns=[\"Time\"])\n",
        "data[\"Amount\"] = StandardScaler().fit_transform(data[[\"Amount\"]])\n",
        "\n",
        "X = data.drop(columns=[\"Class\"]).values\n",
        "y = data[\"Class\"].astype(int).values\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "0XJRDZ3YJmAt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# --- Settings ---\n",
        "RANDOM_SEED = 42\n",
        "TEST_SIZE = 0.3\n",
        "\n",
        "\n",
        "# 再次標準化特徵\n",
        "data_scaler = StandardScaler()\n",
        "X_train = data_scaler.fit_transform(X_train)\n",
        "X_test  = data_scaler.transform(X_test)\n",
        "\n",
        "# --- 使用正常樣本計算最佳 k ---\n",
        "# 抽取前 1000 筆正常樣本\n",
        "norm_samples = X_train[y_train == 0][:1000]\n",
        "# Silhouette 分數列表\n",
        "sil_scores = []\n",
        "for k in range(2, 10):\n",
        "    km = KMeans(\n",
        "        n_clusters=k,\n",
        "        init='k-means++',\n",
        "        random_state=RANDOM_SEED\n",
        "    )\n",
        "    labels = km.fit_predict(norm_samples)\n",
        "    sil_scores.append(silhouette_score(norm_samples, labels))\n",
        "# 選出最佳 k\n",
        "optimal_k = np.argmax(sil_scores) + 2\n",
        "print(f\"Optimal k (2-10) by Silhouette: {optimal_k}\")\n",
        "\n",
        "km_final = KMeans(\n",
        "    n_clusters=optimal_k,\n",
        "    init='k-means++',\n",
        "    n_init=30,\n",
        "    max_iter=700,\n",
        "    tol=1e-4,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "km_final.fit(norm_samples)\n",
        "\n",
        "# 在測試集上分群並對齊標籤\n",
        "labels_test = km_final.predict(X_test)\n",
        "\n",
        "def align_labels(y_true, y_pred, n_clusters):\n",
        "    aligned = np.zeros_like(y_pred)\n",
        "    for i in range(n_clusters):\n",
        "        mask = (y_pred == i)\n",
        "        if np.any(mask):\n",
        "            aligned[mask] = np.bincount(y_true[mask]).argmax()\n",
        "    return aligned\n",
        "\n",
        "y_pred_aligned = align_labels(y_test, labels_test, optimal_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6d3jcLHRr17",
        "outputId": "ed1a861b-20a6-429c-edbd-cdcc16f6b692"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal k (2-10) by Silhouette: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(y_true, y_pred, model_name=\"Model\"):\n",
        "   accuracy = accuracy_score(y_true, y_pred)\n",
        "   precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "   recall = recall_score(y_true, y_pred)\n",
        "   f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "   print(f'\\n{model_name} Evaluation:')\n",
        "   print('===' * 15)\n",
        "   print('         Accuracy:', accuracy)\n",
        "   print('  Precision Score:', precision)\n",
        "   print('     Recall Score:', recall)\n",
        "   print('         F1 Score:', f1)\n",
        "   print(\"\\nClassification Report:\")\n",
        "   print(classification_report(y_true, y_pred))\n",
        "\n",
        "evaluation(y_test, y_pred, model_name=\"KMeans (Unsupervised)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFv9uSnwINpd",
        "outputId": "2e29c0cb-5012-4713-d78e-1b3b5b6a8e32"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "KMeans (Unsupervised) Evaluation:\n",
            "=============================================\n",
            "         Accuracy: 0.9989817773252344\n",
            "  Precision Score: 0.8144329896907216\n",
            "     Recall Score: 0.5337837837837838\n",
            "         F1 Score: 0.6448979591836734\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     85295\n",
            "           1       0.81      0.53      0.64       148\n",
            "\n",
            "    accuracy                           1.00     85443\n",
            "   macro avg       0.91      0.77      0.82     85443\n",
            "weighted avg       1.00      1.00      1.00     85443\n",
            "\n"
          ]
        }
      ]
    }
  ]
}