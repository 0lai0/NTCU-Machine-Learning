### 模型選擇與參數說明

---

#### 監督式學習：`XGBClassifier`（XGBoost）

**選擇理由：**
- 原生支援類別不平衡處理，能有效提升對詐騙樣本（少數類別）的辨識能力。
- 結合梯度提升與決策樹，具備強大非線性建模與特徵擷取能力。
- 執行效率高，並可透過 `scale_pos_weight` 精準調整詐騙樣本的偵測權重。

**參數設定：**
| 參數名稱              | 說明 |
|-----------------------|------|
| `n_estimators=211`    | 樹的數量（弱分類器個數），增加可能提升效果，但會提高訓練成本 |
| `learning_rate=0.168601190206765`| 控制每棵樹對預測的影響，較小值能提升泛化能力但需更多樹 |
| `max_depth=9`         | 控制樹的最大深度，避免過擬合 |
| `subsample=0.9989914764140614`     | 每棵樹訓練使用的樣本比例，有助防止過擬合 |
| `colsample_bytree=0.7464806626828626` | 每棵樹訓練使用的特徵比例，降低特徵干擾 |
| `gamma=0.4911060467180274`         | 分裂節點所需的最小資訊增益，越大越保守 |
| `scale_pos_weight`    | 根據異常/正常樣本比例自動設定，用於平衡類別權重 |
| `min_child_weight=1`  | 限制葉節點最小樣本權重總和，避免學習到噪音 |
| `tree_method='hist'`  | 使用直方圖加速訓練，適合大資料集 |
| `eval_metric='logloss'` | 使用對數損失作為模型效能評估指標 |
| `random_state=42`     | 固定隨機種子，確保結果可重現 |

**參數調整方式：**
- 使用 **Optuna** 進行貝氏最佳化超參調整，能自動尋找效能最佳組合，提升模型效能與泛化能力。

**實驗結果：**

XGBClassifier Evaluation:
```
         Accuracy: 0.9996957035684608
  Precision Score: 0.9365079365079365
     Recall Score: 0.8676470588235294
         F1 Score: 0.9007633587786259

Classification Report:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     85307
           1       0.94      0.87      0.90       136

    accuracy                           1.00     85443
   macro avg       0.97      0.93      0.95     85443
weighted avg       1.00      1.00      1.00     85443
```
---

#### 非監督式學習：`KMeans`

**選擇理由：**
- 雖然非專為異常偵測設計，但搭配後處理策略（如計算群內詐欺率）能達到實用的弱監督異常偵測效果。
- 對資料結構有假設前提（分群），適合探索資料潛在分布與異常點聚集。

**參數設定：**
| 參數名稱            | 說明 |
|---------------------|------|
| `n_clusters=8`      | 聚類群數，控制分群的細緻程度 |
| `init='k-means++'`  | 初始化方法，避免隨機初始化導致的不穩定性 |
| `n_init=39`         | 執行 KMeans 的初始化次數，取最佳結果，有助提高穩定性 |
| `tol=...`（註解掉） | 收斂誤差容忍度，用來提早終止訓練，但本次未啟用 |

**後處理邏輯：**
1. 使用正常樣本訓練 KMeans。
2. 對測試集進行分群，並統計各群的詐欺樣本比例。
3. 若某群內詐欺比例高於整體平均，即將該群標為「異常」。
4. 以此將測試資料標記為異常（1）或正常（0）。

**實驗結果：**

KMeans (Unsupervised) Evaluation:
```
         Accuracy: 0.7668918918918919
  Precision Score: 0.8434782608695652
     Recall Score: 0.6554054054054054
         F1 Score: 0.7376425855513308

Classification Report:
              precision    recall  f1-score   support

         0.0       0.72      0.88      0.79       148
         1.0       0.84      0.66      0.74       148

    accuracy                           0.77       296
   macro avg       0.78      0.77      0.76       296
weighted avg       0.78      0.77      0.76       296
```

---

#### 嘗試過但棄用的非監督方法：`IsolationForest`

**嘗試理由：**
- 專為異常偵測設計，特別適用於詐騙資料這種嚴重不平衡問題。
- 不依賴標籤，適合實務中異常樣本難以蒐集的情境。

**放棄原因：**
- 實驗中 `F1-score` 始終無法超過 0.4，導致預測效果不穩定。
- 經比較後，KMeans（搭配後處理）在此資料集的表現較佳。